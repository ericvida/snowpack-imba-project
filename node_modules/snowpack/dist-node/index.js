'use strict';

Object.defineProperty(exports, '__esModule', { value: true });

function _interopDefault (ex) { return (ex && (typeof ex === 'object') && 'default' in ex) ? ex['default'] : ex; }

var colors = require('kleur/colors');
var path = _interopDefault(require('path'));
var yargs = _interopDefault(require('yargs-parser'));
var fs = require('fs');
var fs__default = _interopDefault(fs);
var got = _interopDefault(require('got'));
var rollupPluginAlias = _interopDefault(require('@rollup/plugin-alias'));
var rollupPluginCommonjs = _interopDefault(require('@rollup/plugin-commonjs'));
var rollupPluginJson = _interopDefault(require('@rollup/plugin-json'));
var rollupPluginNodeResolve = _interopDefault(require('@rollup/plugin-node-resolve'));
var rollupPluginReplace = _interopDefault(require('@rollup/plugin-replace'));
var esModuleLexer = require('es-module-lexer');
var findUp = _interopDefault(require('find-up'));
var mkdirp = _interopDefault(require('mkdirp'));
var ora = _interopDefault(require('ora'));
var perf_hooks = require('perf_hooks');
var rimraf = _interopDefault(require('rimraf'));
var rollup = require('rollup');
var validatePackageName = _interopDefault(require('validate-npm-package-name'));
var cacache = _interopDefault(require('cacache'));
var PQueue = _interopDefault(require('p-queue'));
var globalCacheDir = _interopDefault(require('cachedir'));
var etag = _interopDefault(require('etag'));
var execa = _interopDefault(require('execa'));
var projectCacheDir = _interopDefault(require('find-cache-dir'));
var open = _interopDefault(require('open'));
var isNodeBuiltin = _interopDefault(require('is-builtin-module'));
var tar = _interopDefault(require('tar'));
var url = _interopDefault(require('url'));
var zlib = _interopDefault(require('zlib'));
var glob = _interopDefault(require('glob'));
var mime = _interopDefault(require('mime-types'));
var stripComments = _interopDefault(require('strip-comments'));
var merge = require('deepmerge');
var merge__default = _interopDefault(merge);
var esbuild = require('esbuild');
var events = require('events');
var util = _interopDefault(require('util'));
var buildScriptPlugin = _interopDefault(require('@snowpack/plugin-build-script'));
var runScriptPlugin = _interopDefault(require('@snowpack/plugin-run-script'));
var cosmiconfig = require('cosmiconfig');
var jsonschema = require('jsonschema');
var isCompressible = _interopDefault(require('compressible'));
var http = _interopDefault(require('http'));
var HttpProxy = _interopDefault(require('http-proxy'));
var http2 = _interopDefault(require('http2'));
var https = _interopDefault(require('https'));
var npmRunPath = _interopDefault(require('npm-run-path'));
var os = _interopDefault(require('os'));
var onProcessExit = _interopDefault(require('signal-exit'));
var stream = _interopDefault(require('stream'));
var WebSocket = _interopDefault(require('ws'));
var detectPort = _interopDefault(require('detect-port'));
var readline = _interopDefault(require('readline'));

function _defineProperty(obj, key, value) {
  if (key in obj) {
    Object.defineProperty(obj, key, {
      value: value,
      enumerable: true,
      configurable: true,
      writable: true
    });
  } else {
    obj[key] = value;
  }

  return obj;
}

function ownKeys(object, enumerableOnly) {
  var keys = Object.keys(object);

  if (Object.getOwnPropertySymbols) {
    var symbols = Object.getOwnPropertySymbols(object);
    if (enumerableOnly) symbols = symbols.filter(function (sym) {
      return Object.getOwnPropertyDescriptor(object, sym).enumerable;
    });
    keys.push.apply(keys, symbols);
  }

  return keys;
}

function _objectSpread2(target) {
  for (var i = 1; i < arguments.length; i++) {
    var source = arguments[i] != null ? arguments[i] : {};

    if (i % 2) {
      ownKeys(Object(source), true).forEach(function (key) {
        _defineProperty(target, key, source[key]);
      });
    } else if (Object.getOwnPropertyDescriptors) {
      Object.defineProperties(target, Object.getOwnPropertyDescriptors(source));
    } else {
      ownKeys(Object(source)).forEach(function (key) {
        Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key));
      });
    }
  }

  return target;
}

function _objectWithoutPropertiesLoose(source, excluded) {
  if (source == null) return {};
  var target = {};
  var sourceKeys = Object.keys(source);
  var key, i;

  for (i = 0; i < sourceKeys.length; i++) {
    key = sourceKeys[i];
    if (excluded.indexOf(key) >= 0) continue;
    target[key] = source[key];
  }

  return target;
}

function _objectWithoutProperties(source, excluded) {
  if (source == null) return {};

  var target = _objectWithoutPropertiesLoose(source, excluded);

  var key, i;

  if (Object.getOwnPropertySymbols) {
    var sourceSymbolKeys = Object.getOwnPropertySymbols(source);

    for (i = 0; i < sourceSymbolKeys.length; i++) {
      key = sourceSymbolKeys[i];
      if (excluded.indexOf(key) >= 0) continue;
      if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue;
      target[key] = source[key];
    }
  }

  return target;
}

const PIKA_CDN = `https://cdn.pika.dev`;
const GLOBAL_CACHE_DIR = globalCacheDir('snowpack'); // A note on cache naming/versioning: We currently version our global caches
// with the version of the last breaking change. This allows us to re-use the
// same cache across versions until something in the data structure changes.
// At that point, bump the version in the cache name to create a new unique
// cache name.

const RESOURCE_CACHE = path.join(GLOBAL_CACHE_DIR, 'pkg-cache-1.4');
const BUILD_CACHE = path.join(GLOBAL_CACHE_DIR, 'build-cache-2.6');
const PROJECT_CACHE_DIR = projectCacheDir({
  name: 'snowpack'
});
const DEV_DEPENDENCIES_DIR = path.join(PROJECT_CACHE_DIR, 'dev');
const LOCKFILE_HASH_FILE = '.hash';
const HAS_CDN_HASH_REGEX = /\-[a-zA-Z0-9]{16,}/; // NOTE(fks): Must match empty script elements to work properly.

const HTML_JS_REGEX = /(<script[\s\S]*?type="?module"?[\s\S]*?>)([\s\S]*?)<\/script>/gm;
const URL_HAS_PROTOCOL_REGEX = /^(\w+:)?\/\//;
function isYarn(cwd) {
  return fs__default.existsSync(path.join(cwd, 'yarn.lock'));
}
const UTF8_FORMATS = ['.css', '.html', '.js', '.mjs', '.json', '.svg', '.txt', '.xml'];
function getEncodingType(ext) {
  return UTF8_FORMATS.includes(ext) ? 'utf-8' : 'binary';
}
async function readLockfile(cwd) {
  try {
    var lockfileContents = fs__default.readFileSync(path.join(cwd, 'snowpack.lock.json'), {
      encoding: 'utf-8'
    });
  } catch (err) {
    // no lockfile found, ignore and continue
    return null;
  } // If this fails, we actually do want to alert the user by throwing


  return JSON.parse(lockfileContents);
}
async function writeLockfile(loc, importMap) {
  const sortedImportMap = {
    imports: {}
  };

  for (const key of Object.keys(importMap.imports).sort()) {
    sortedImportMap.imports[key] = importMap.imports[key];
  }

  fs__default.writeFileSync(loc, JSON.stringify(sortedImportMap, undefined, 2), {
    encoding: 'utf-8'
  });
}
function fetchCDNResource(resourceUrl, responseType) {
  if (!resourceUrl.startsWith(PIKA_CDN)) {
    resourceUrl = PIKA_CDN + resourceUrl;
  } // @ts-ignore - TS doesn't like responseType being unknown amount three options


  return got(resourceUrl, {
    responseType: responseType,
    headers: {
      'user-agent': `snowpack/v1.4 (https://snowpack.dev)`
    },
    throwHttpErrors: false
  });
}
function isTruthy(item) {
  return Boolean(item);
}
/** Get the package name + an entrypoint within that package (if given). */

function parsePackageImportSpecifier(imp) {
  const impParts = imp.split('/');

  if (imp.startsWith('@')) {
    const [scope, name, ...rest] = impParts;
    return [`${scope}/${name}`, rest.join('/') || null];
  }

  const [name, ...rest] = impParts;
  return [name, rest.join('/') || null];
}
/**
 * Given a package name, look for that package's package.json manifest.
 * Return both the manifest location (if believed to exist) and the
 * manifest itself (if found).
 *
 * NOTE: You used to be able to require() a package.json file directly,
 * but now with export map support in Node v13 that's no longer possible.
 */

function resolveDependencyManifest(dep, cwd) {
  // Attempt #1: Resolve the dependency manifest normally. This works for most
  // packages, but fails when the package defines an export map that doesn't
  // include a package.json. If we detect that to be the reason for failure,
  // move on to our custom implementation.
  try {
    const depManifest = require.resolve(`${dep}/package.json`, {
      paths: [cwd]
    });

    return [depManifest, require(depManifest)];
  } catch (err) {
    // if its an export map issue, move on to our manual resolver.
    if (err.code !== 'ERR_PACKAGE_PATH_NOT_EXPORTED') {
      return [null, null];
    }
  } // Attempt #2: Resolve the dependency manifest manually. This involves resolving
  // the dep itself to find the entrypoint file, and then haphazardly replacing the
  // file path within the package with a "./package.json" instead. It's not as
  // thorough as Attempt #1, but it should work well until export maps become more
  // established & move out of experimental mode.


  let result = [null, null];

  try {
    const fullPath = require.resolve(dep, {
      paths: [cwd]
    }); // Strip everything after the package name to get the package root path
    // NOTE: This find-replace is very gross, replace with something like upath.


    const searchPath = `${path.sep}node_modules${path.sep}${dep.replace('/', path.sep)}`;
    const indexOfSearch = fullPath.lastIndexOf(searchPath);

    if (indexOfSearch >= 0) {
      const manifestPath = fullPath.substring(0, indexOfSearch + searchPath.length + 1) + 'package.json';
      result[0] = manifestPath;
      const manifestStr = fs__default.readFileSync(manifestPath, {
        encoding: 'utf-8'
      });
      result[1] = JSON.parse(manifestStr);
    }
  } catch (err) {// ignore
  } finally {
    return result;
  }
}
/**
 * If Rollup erred parsing a particular file, show suggestions based on its
 * file extension (note: lowercase is fine).
 */

const MISSING_PLUGIN_SUGGESTIONS = {
  '.svelte': 'Try installing rollup-plugin-svelte and adding it to Snowpack (https://www.snowpack.dev/#custom-rollup-plugins)',
  '.vue': 'Try installing rollup-plugin-vue and adding it to Snowpack (https://www.snowpack.dev/#custom-rollup-plugins)'
};
const appNames = {
  win32: {
    brave: 'brave',
    chrome: 'chrome'
  },
  darwin: {
    brave: 'Brave Browser',
    chrome: 'Google Chrome'
  },
  linux: {
    brave: 'brave',
    chrome: 'google-chrome'
  }
};
async function openInBrowser(protocol, hostname, port, browser) {
  const url = `${protocol}//${hostname}:${port}`;
  browser = /chrome/i.test(browser) ? appNames[process.platform]['chrome'] : /brave/i.test(browser) ? appNames[process.platform]['brave'] : browser;

  if (process.platform === 'darwin' && /chrome|default/i.test(browser)) {
    // If we're on macOS, and we haven't requested a specific browser,
    // we can try opening Chrome with AppleScript. This lets us reuse an
    // existing tab when possible instead of creating a new one.
    try {
      await execa.command('ps cax | grep "Google Chrome"', {
        shell: true
      });
      await execa('osascript ../assets/openChrome.applescript "' + encodeURI(url) + '"', {
        cwd: __dirname,
        stdio: 'ignore',
        shell: true
      });
      return true;
    } catch (err) {
      // If macOS auto-reuse doesn't work, just open normally, using default browser.
      open(url);
    }
  } else {
    browser === 'default' ? open(url) : open(url, {
      app: browser
    });
  }
}
async function checkLockfileHash(dir) {
  const lockfileLoc = await findUp(['package-lock.json', 'yarn.lock']);

  if (!lockfileLoc) {
    return true;
  }

  const hashLoc = path.join(dir, LOCKFILE_HASH_FILE);
  const newLockHash = etag(await fs__default.promises.readFile(lockfileLoc, 'utf-8'));
  const oldLockHash = await fs__default.promises.readFile(hashLoc, 'utf-8').catch(() => '');
  return newLockHash === oldLockHash;
}
async function updateLockfileHash(dir) {
  const lockfileLoc = await findUp(['package-lock.json', 'yarn.lock']);

  if (!lockfileLoc) {
    return;
  }

  const hashLoc = path.join(dir, LOCKFILE_HASH_FILE);
  const newLockHash = etag(await fs__default.promises.readFile(lockfileLoc));
  await mkdirp(path.dirname(hashLoc));
  await fs__default.promises.writeFile(hashLoc, newLockHash);
}
async function clearCache() {
  return Promise.all([cacache.rm.all(RESOURCE_CACHE), cacache.rm.all(BUILD_CACHE), rimraf.sync(PROJECT_CACHE_DIR)]);
}
/**
 * For the given import specifier, return an alias entry if one is matched.
 */

function findMatchingAliasEntry(config, spec) {
  // Only match bare module specifiers. relative and absolute imports should not match
  if (spec.startsWith('./') || spec.startsWith('../') || spec.startsWith('/') || spec.startsWith('http://') || spec.startsWith('https://')) {
    return undefined;
  }

  const foundEntry = Object.entries(config.alias).find(([fromAlias]) => spec.startsWith(fromAlias));

  if (!foundEntry) {
    return undefined;
  }

  return {
    from: foundEntry[0],
    to: foundEntry[1],
    type: isPackageAliasEntry(foundEntry[1]) ? 'package' : 'path'
  };
}
/**
 * For the given import specifier, return an alias entry if one is matched.
 */

function isPackageAliasEntry(val) {
  return !path.isAbsolute(val);
}
/** Get full extensions of files */

function getExt(fileName) {
  return {
    /** base extension (e.g. `.js`) */
    baseExt: path.extname(fileName).toLocaleLowerCase(),

    /** full extension, if applicable (e.g. `.proxy.js`) */
    expandedExt: path.basename(fileName).replace(/[^.]+/, '').toLocaleLowerCase()
  };
}
/** Replace file extensions */

function replaceExt(fileName, newExtension, replaceExpandedExt = false) {
  const {
    baseExt,
    expandedExt
  } = getExt(fileName);
  const extToReplace = new RegExp(`\\${replaceExpandedExt ? expandedExt : baseExt}$`, 'i');
  return fileName.replace(extToReplace, newExtension);
}
/**
 * Sanitizes npm packages that end in .js (e.g `tippy.js` -> `tippyjs`).
 * This is necessary because Snowpack can’t create both a file and directory
 * that end in .js.
 */

function sanitizePackageName(filepath) {
  const dirs = filepath.split('/');
  const file = dirs.pop();
  return [...dirs.map(path => path.replace(/\.js$/i, 'js')), file].join('/');
}

/**
 * Given an install specifier, attempt to resolve it from the CDN.
 * If no lockfile exists or if the entry is not found in the lockfile, attempt to resolve
 * it from the CDN directly. Otherwise, use the URL found in the lockfile and attempt to
 * check the local cache first.
 *
 * All resolved URLs are populated into the local cache, where our internal Rollup engine
 * will load them from when it installs your dependencies to disk.
 */

async function resolveDependency(installSpecifier, packageSemver, lockfile, canRetry = true) {
  // Right now, the CDN is only for top-level JS packages. The CDN doesn't support CSS,
  // non-JS assets, and has limited support for deep package imports. Snowpack
  // will automatically fall-back any failed/not-found assets from local
  // node_modules/ instead.
  if (!validatePackageName(installSpecifier).validForNewPackages) {
    return null;
  } // Grab the installUrl from our lockfile if it exists, otherwise resolve it yourself.


  let installUrl;
  let installUrlType;

  if (lockfile && lockfile.imports[installSpecifier]) {
    installUrl = lockfile.imports[installSpecifier];
    installUrlType = 'pin';
  } else {
    if (packageSemver === 'latest') {
      console.warn(`warn(${installSpecifier}): Not found in "dependencies". Using latest package version...`);
    }

    if (packageSemver.startsWith('npm:@reactesm') || packageSemver.startsWith('npm:@pika/react')) {
      throw new Error(`React workaround packages no longer needed! Revert to the official React & React-DOM packages.`);
    }

    if (packageSemver.includes(' ') || packageSemver.includes(':')) {
      console.warn(`warn(${installSpecifier}): Can't fetch complex semver "${packageSemver}" from remote CDN.`);
      return null;
    }

    installUrlType = 'lookup';
    installUrl = `${PIKA_CDN}/${installSpecifier}@${packageSemver}`;
  } // Hashed CDN urls never change, so its safe to grab them directly from the local cache
  // without a network request.


  if (installUrlType === 'pin') {
    const cachedResult = await cacache.get.info(RESOURCE_CACHE, installUrl).catch(() => null);

    if (cachedResult) {
      if (cachedResult.metadata) {
        const {
          pinnedUrl
        } = cachedResult.metadata;
        return pinnedUrl;
      }
    }
  } // Otherwise, resolve from the CDN remotely.


  const {
    statusCode,
    headers,
    body
  } = await fetchCDNResource(installUrl);

  if (statusCode !== 200) {
    console.warn(`Failed to resolve [${statusCode}]: ${installUrl} (${body})`);
    console.warn(`Falling back to local copy...`);
    return null;
  }

  let importUrlPath = headers['x-import-url'];
  let pinnedUrlPath = headers['x-pinned-url'];
  const buildStatus = headers['x-import-status'];
  const typesUrlPath = headers['x-typescript-types'];
  const typesUrl = typesUrlPath && `${PIKA_CDN}${typesUrlPath}`;

  if (installUrlType === 'pin') {
    const pinnedUrl = installUrl;
    await cacache.put(RESOURCE_CACHE, pinnedUrl, body, {
      metadata: {
        pinnedUrl,
        typesUrl
      }
    });
    return pinnedUrl;
  }

  if (pinnedUrlPath) {
    const pinnedUrl = `${PIKA_CDN}${pinnedUrlPath}`;
    await cacache.put(RESOURCE_CACHE, pinnedUrl, body, {
      metadata: {
        pinnedUrl,
        typesUrl
      }
    });
    return pinnedUrl;
  }

  if (buildStatus === 'SUCCESS') {
    console.warn(`Failed to lookup [${statusCode}]: ${installUrl}`);
    console.warn(`Falling back to local copy...`);
    return null;
  }

  if (!canRetry || buildStatus === 'FAIL') {
    console.warn(`Failed to build: ${installSpecifier}@${packageSemver}`);
    console.warn(`Falling back to local copy...`);
    return null;
  }

  console.log(colors.cyan(`Building ${installSpecifier}@${packageSemver}... (This takes a moment, but will be cached for future use)`));

  if (!importUrlPath) {
    throw new Error('X-Import-URL header expected, but none received.');
  }

  const {
    statusCode: lookupStatusCode
  } = await fetchCDNResource(importUrlPath);

  if (lookupStatusCode !== 200) {
    throw new Error(`Unexpected response [${lookupStatusCode}]: ${PIKA_CDN}${importUrlPath}`);
  }

  return resolveDependency(installSpecifier, packageSemver, lockfile, false);
}

async function resolveTargetsFromRemoteCDN(lockfile, config) {
  const downloadQueue = new PQueue({
    concurrency: 16
  });
  const newLockfile = {
    imports: {}
  };
  let resolutionError;

  for (const [installSpecifier, installSemver] of Object.entries(config.webDependencies)) {
    downloadQueue.add(async () => {
      try {
        const resolvedUrl = await resolveDependency(installSpecifier, installSemver, lockfile);

        if (resolvedUrl) {
          newLockfile.imports[installSpecifier] = resolvedUrl;
        }
      } catch (err) {
        resolutionError = resolutionError || err;
      }
    });
  }

  await downloadQueue.onIdle();

  if (resolutionError) {
    throw resolutionError;
  }

  return newLockfile;
}

/**
 * rollup-plugin-catch-unresolved
 *
 * Catch any unresolved imports to give proper warnings (Rollup default is to ignore).
 */

function rollupPluginCatchUnresolved() {
  return {
    name: 'snowpack:rollup-plugin-catch-unresolved',

    resolveId(id, importer) {
      // Ignore remote http/https imports
      if (id.startsWith('http://') || id.startsWith('https://')) {
        return false;
      }

      if (isNodeBuiltin(id)) {
        this.warn({
          id: importer,
          message: `"${id}" (Node.js built-in) could not be resolved. (https://www.snowpack.dev/#node-built-in-could-not-be-resolved)`
        });
      } else {
        this.warn({
          id: importer,
          message: `"${id}" could not be resolved. (Is it installed?)`
        });
      }

      return false;
    }

  };
}

const FETCH_POLYFILL = `
// native patch for: node-fetch, whatwg-fetch
// ref: https://github.com/tc39/proposal-global
var getGlobal = function () {
  if (typeof self !== 'undefined') { return self; }
  if (typeof window !== 'undefined') { return window; }
  if (typeof global !== 'undefined') { return global; }
  throw new Error('unable to locate global object');
}
var global = getGlobal();
export default global.fetch.bind(global);
export const Headers = global.Headers;
export const Request = global.Request;
export const Response = global.Response;
`;
/**
 * rollup-plugin-catch-fetch
 *
 * How it works: NPM packages will sometimes contain Node.js-specific polyfills
 * for the native browser Fetch API. Since this makes no sense in an ESM web
 * project, we can replace these expensive polyfills with native references to
 * the fetch API.
 *
 * This still allows you to polyfill fetch in older browsers, if you desire.
 */

function rollupPluginCatchFetch() {
  return {
    name: 'snowpack:fetch-handler',

    resolveId(id) {
      if (id !== 'node-fetch' && id !== 'whatwg-fetch') {
        return null;
      }

      return id;
    },

    load(id) {
      if (id !== 'node-fetch' && id !== 'whatwg-fetch') {
        return null;
      }

      return FETCH_POLYFILL;
    }

  };
}

function getInjectorCode(name, code) {
  return `
/** SNOWPACK INJECT STYLE: ${name} */
function __snowpack__injectStyle(css) {
  const headEl = document.head || document.getElementsByTagName('head')[0];
  const styleEl = document.createElement('style');
  styleEl.type = 'text/css';
  if (styleEl.styleSheet) {
    styleEl.styleSheet.cssText = css;
  } else {
    styleEl.appendChild(document.createTextNode(css));
  }
  headEl.appendChild(styleEl);
}
__snowpack__injectStyle(${JSON.stringify(code)});\n`;
}
/**
 * rollup-plugin-css
 *
 * Support installing any imported CSS into your dependencies. This isn't strictly valid
 * ESM code, but it is popular in the npm ecosystem & web development ecosystems. It also
 * solves a problem that is difficult to solve otherwise (referencing CSS from JS) so for
 * those reasons we have added default support for importing CSS into Snowpack v2.
 */


function rollupPluginCss() {
  return {
    name: 'snowpack:rollup-plugin-css',

    resolveId(source, importer) {
      if (!source.endsWith('.css')) {
        return null;
      }

      return this.resolve(source, importer, {
        skipSelf: true
      }).then(resolved => {
        return resolved || null;
      });
    },

    async load(id) {
      if (!id.endsWith('.css')) {
        return null;
      }

      const code = await fs.promises.readFile(id, {
        encoding: 'utf-8'
      });
      const humanReadableName = id.replace(/.*node_modules[\/\\]/, '').replace(/[\/\\]/g, '/');
      return getInjectorCode(humanReadableName, code);
    }

  };
}

const CACHED_FILE_ID_PREFIX = 'snowpack-pkg-cache:';
const PIKA_CDN_TRIM_LENGTH = PIKA_CDN.length;
/**
 * rollup-plugin-remote-cdn
 *
 * Load import URLs from a remote CDN, sitting behind a local cache. The local
 * cache acts as a go-between for the resolve & load step: when we get back a
 * successful CDN resolution, we save the file to the local cache and then tell
 * rollup that it's safe to load from the cache in the `load()` hook.
 */

function rollupPluginDependencyCache({
  installTypes,
  log
}) {
  const allTypesToInstall = new Set();
  return {
    name: 'snowpack:rollup-plugin-remote-cdn',

    async resolveId(source, importer) {
      let cacheKey;

      if (source.startsWith(PIKA_CDN)) {
        cacheKey = source;
      } else if (source.startsWith('/-/')) {
        cacheKey = PIKA_CDN + source;
      } else if (source.startsWith('/pin/')) {
        cacheKey = PIKA_CDN + source;
      } else {
        return null;
      } // If the source path is a CDN path including a hash, it's assumed the
      // file will never change and it is safe to pull from our local cache
      // without a network request.


      log(cacheKey);

      if (HAS_CDN_HASH_REGEX.test(cacheKey)) {
        const cachedResult = await cacache.get.info(RESOURCE_CACHE, cacheKey).catch(() =>
        /* ignore */
        null);

        if (cachedResult) {
          return CACHED_FILE_ID_PREFIX + cacheKey;
        }
      } // Otherwise, make the remote request and cache the file on success.


      const response = await fetchCDNResource(cacheKey);

      if (response.statusCode === 200) {
        const typesUrlPath = response.headers['x-typescript-types'];
        const pinnedUrlPath = response.headers['x-pinned-url'];
        const typesUrl = typesUrlPath && `${PIKA_CDN}${typesUrlPath}`;
        const pinnedUrl = pinnedUrlPath && `${PIKA_CDN}${pinnedUrlPath}`;
        await cacache.put(RESOURCE_CACHE, cacheKey, response.body, {
          metadata: {
            pinnedUrl,
            typesUrl
          }
        });
        return CACHED_FILE_ID_PREFIX + cacheKey;
      } // If lookup failed, skip this plugin and resolve the import locally instead.
      // TODO: Log that this has happened (if some sort of verbose mode is enabled).


      const packageName = cacheKey.substring(PIKA_CDN_TRIM_LENGTH).replace('/-/', '').replace('/pin/', '').split('@')[0];
      return this.resolve(packageName, importer, {
        skipSelf: true
      }).then(resolved => {
        let finalResult = resolved;

        if (!finalResult) {
          finalResult = {
            id: packageName
          };
        }

        return finalResult;
      });
    },

    async load(id) {
      var _cachedResult$metadat;

      if (!id.startsWith(CACHED_FILE_ID_PREFIX)) {
        return null;
      }

      const cacheKey = id.substring(CACHED_FILE_ID_PREFIX.length);
      log(cacheKey);
      const cachedResult = await cacache.get(RESOURCE_CACHE, cacheKey);
      const typesUrl = (_cachedResult$metadat = cachedResult.metadata) === null || _cachedResult$metadat === void 0 ? void 0 : _cachedResult$metadat.typesUrl;

      if (typesUrl && installTypes) {
        const typesTarballUrl = typesUrl.replace(/(mode=types.*?)\/.*/, '$1/all.tgz');
        allTypesToInstall.add(typesTarballUrl);
      }

      return cachedResult.data.toString('utf-8');
    },

    async writeBundle(options) {
      if (!installTypes) {
        return;
      }

      await mkdirp(path.join(options.dir, '.types'));
      const tempDir = await cacache.tmp.mkdir(RESOURCE_CACHE);

      for (const typesTarballUrl of allTypesToInstall) {
        let tarballContents;
        const cachedTarball = await cacache.get(RESOURCE_CACHE, typesTarballUrl).catch(() =>
        /* ignore */
        null);

        if (cachedTarball) {
          tarballContents = cachedTarball.data;
        } else {
          const tarballResponse = await fetchCDNResource(typesTarballUrl, 'buffer');

          if (tarballResponse.statusCode !== 200) {
            continue;
          }

          tarballContents = tarballResponse.body;
          await cacache.put(RESOURCE_CACHE, typesTarballUrl, tarballContents);
        }

        const typesUrlParts = url.parse(typesTarballUrl).pathname.split('/');
        const typesPackageName = url.parse(typesTarballUrl).pathname.startsWith('/-/@') ? typesUrlParts[2] + '/' + typesUrlParts[3].split('@')[0] : typesUrlParts[2].split('@')[0];
        const typesPackageTarLoc = path.join(tempDir, `${typesPackageName}.tgz`);

        if (typesPackageName.includes('/')) {
          await mkdirp(path.dirname(typesPackageTarLoc));
        }

        fs__default.writeFileSync(typesPackageTarLoc, tarballContents);
        const typesPackageLoc = path.join(options.dir, `.types/${typesPackageName}`);
        await mkdirp(typesPackageLoc);
        await tar.x({
          file: typesPackageTarLoc,
          cwd: typesPackageLoc
        });
      }
    }

  };
}

function rollupPluginDependencyStats(cb) {
  let outputDir;
  let existingFileCache = {};
  let statsSummary = {
    direct: {},
    common: {}
  };

  function buildExistingFileCache(bundle) {
    for (let fileName of Object.keys(bundle)) {
      const filePath = path.join(outputDir, fileName);

      if (fs__default.existsSync(filePath)) {
        const {
          size
        } = fs__default.statSync(filePath);
        existingFileCache[fileName] = size;
      }
    }
  }

  function compareDependencies(files, type) {
    for (let {
      fileName,
      contents
    } of files) {
      const size = contents.byteLength;
      statsSummary[type][fileName] = {
        size: size,
        gzip: zlib.gzipSync(contents).byteLength,
        brotli: zlib.brotliCompressSync ? zlib.brotliCompressSync(contents).byteLength : 0
      };

      if (existingFileCache[fileName]) {
        const delta = (size - existingFileCache[fileName]) / 1000;
        statsSummary[type][fileName].delta = delta;
      }
    }
  }

  return {
    name: 'snowpack:rollup-plugin-stats',

    generateBundle(options, bundle) {
      outputDir = options.dir;
      buildExistingFileCache(bundle);
    },

    writeBundle(_, bundle) {
      const directDependencies = [];
      const commonDependencies = [];

      for (const [fileName, assetOrChunk] of Object.entries(bundle)) {
        const raw = assetOrChunk.type === 'asset' ? assetOrChunk.source : assetOrChunk.code;
        const contents = Buffer.isBuffer(raw) ? raw : typeof raw === 'string' ? Buffer.from(raw, 'utf-8') : Buffer.from(raw);

        if (fileName.startsWith('common')) {
          commonDependencies.push({
            fileName,
            contents
          });
        } else {
          directDependencies.push({
            fileName,
            contents
          });
        }
      }

      compareDependencies(directDependencies, 'direct');
      compareDependencies(commonDependencies, 'common');
      cb(statsSummary);
    }

  };
}

function autoDetectExports(fileLoc) {
  try {
    return Object.keys(require(fileLoc));
  } catch (err) {
    console.error(colors.red(`✘ Could not auto-detect exports for ${colors.bold(fileLoc)}\n${err.message}`));
  }
}
/**
 * rollup-plugin-wrap-install-targets
 *
 * How it works:
 * 1. An array of "install targets" are passed in, describing all known imports + metadata.
 * 2. If isTreeshake: Known imports are marked for tree-shaking by appending 'snowpack-wrap:' to the input value.
 * 3. If autoDetectPackageExports match: Also mark for wrapping, and use automatic export detection.
 * 4. On load, we return a false virtual file for all "snowpack-wrap:" inputs.
 *    a. That virtual file contains only `export ... from 'ACTUAL_FILE_PATH';` exports
 *    b. Rollup uses those exports to drive its tree-shaking algorithm.
 *    c. Rollup uses those exports to inform its "namedExports" for Common.js entrypoints.
 */


function rollupPluginWrapInstallTargets(isTreeshake, autoDetectPackageExports, installTargets) {
  const installTargetsByFile = {};

  function isAutoDetect(normalizedFileLoc) {
    return autoDetectPackageExports.some(p => normalizedFileLoc.includes(`node_modules/${p}${p.endsWith('index.js') ? '' : '/'}`));
  }

  return {
    name: 'snowpack:wrap-install-targets',

    // Mark some inputs for tree-shaking.
    options(inputOptions) {
      const input = inputOptions.input;

      for (const [key, val] of Object.entries(input)) {
        installTargetsByFile[val] = installTargets.filter(imp => imp.specifier === key);

        if (isTreeshake && installTargetsByFile[val].length > 0 && !installTargetsByFile[val].some(imp => imp.namespace || imp.all)) {
          input[key] = `snowpack-wrap:${val}`;
        }

        if (!isTreeshake) {
          const normalizedFileLoc = val.split(path.win32.sep).join(path.posix.sep);

          if (isAutoDetect(normalizedFileLoc)) {
            input[key] = `snowpack-wrap:${val}`;
          }
        }
      }

      return inputOptions;
    },

    resolveId(source) {
      if (source.startsWith('snowpack-wrap:')) {
        return source;
      }

      return null;
    },

    load(id) {
      if (!id.startsWith('snowpack-wrap:')) {
        return null;
      }

      const fileLoc = id.substring('snowpack-wrap:'.length); // Reduce all install targets into a single "summarized" install target.

      const treeshakeSummary = installTargetsByFile[fileLoc].reduce((summary, imp) => {
        summary.default = summary.default || imp.default;
        summary.namespace = summary.namespace || imp.namespace;
        summary.named = [...summary.named, ...imp.named];
        return summary;
      });
      let uniqueNamedImports = Array.from(new Set(treeshakeSummary.named));
      const normalizedFileLoc = fileLoc.split(path.win32.sep).join(path.posix.sep);

      if (!isTreeshake && isAutoDetect(normalizedFileLoc)) {
        uniqueNamedImports = autoDetectExports(fileLoc) || uniqueNamedImports;
        treeshakeSummary.default = true;
      }

      const result = `
        ${treeshakeSummary.namespace ? `export * from '${normalizedFileLoc}';` : ''}
        ${treeshakeSummary.default ? `import __pika_web_default_export_for_treeshaking__ from '${normalizedFileLoc}'; export default __pika_web_default_export_for_treeshaking__;` : ''}
        ${`export {${uniqueNamedImports.join(',')}} from '${normalizedFileLoc}';`}
      `;
      return result;
    }

  };
}

const WEB_MODULES_TOKEN = 'web_modules/';
const WEB_MODULES_TOKEN_LENGTH = WEB_MODULES_TOKEN.length; // [@\w] - Match a word-character or @ (valid package name)
// (?!.*(:\/\/)) - Ignore if previous match was a protocol (ex: http://)

const BARE_SPECIFIER_REGEX = /^[@\w](?!.*(:\/\/))/;
const ESM_IMPORT_REGEX = /import(?:["'\s]*([\w*${}\n\r\t, ]+)\s*from\s*)?\s*["'](.*?)["']/gm;
const ESM_DYNAMIC_IMPORT_REGEX = /import\((?:['"].+['"]|`[^$]+`)\)/gm;
const HAS_NAMED_IMPORTS_REGEX = /^[\t-\r ,0-9A-Z_a-z\xA0\u1680\u2000-\u200A\u2028\u2029\u202F\u205F\u3000\uFEFF]*\{([\s\S]*)\}/;
const STRIP_AS = /\s+as\s+.*/; // for `import { foo as bar }`, strips “as bar”

const DEFAULT_IMPORT_REGEX = /import[\t-\r \xA0\u1680\u2000-\u200A\u2028\u2029\u202F\u205F\u3000\uFEFF]+([0-9A-Z_a-z])+(,[\t-\r \xA0\u1680\u2000-\u200A\u2028\u2029\u202F\u205F\u3000\uFEFF]\{[\t-\r 0-9A-Z_a-z\xA0\u1680\u2000-\u200A\u2028\u2029\u202F\u205F\u3000\uFEFF]*\})?[\t-\r \xA0\u1680\u2000-\u200A\u2028\u2029\u202F\u205F\u3000\uFEFF]+from/;

function stripJsExtension(dep) {
  return dep.replace(/\.m?js$/i, '');
}

function createInstallTarget(specifier, all = true) {
  return {
    specifier,
    all,
    default: false,
    namespace: false,
    named: []
  };
}

function removeSpecifierQueryString(specifier) {
  const queryStringIndex = specifier.indexOf('?');

  if (queryStringIndex >= 0) {
    specifier = specifier.substring(0, queryStringIndex);
  }

  return specifier;
}

function getWebModuleSpecifierFromCode(code, imp) {
  // import.meta: we can ignore
  if (imp.d === -2) {
    return null;
  } // Static imports: easy to parse


  if (imp.d === -1) {
    return code.substring(imp.s, imp.e);
  } // Dynamic imports: a bit trickier to parse. Today, we only support string literals.


  const importStatement = code.substring(imp.s, imp.e);
  const importSpecifierMatch = importStatement.match(/^\s*['"](.*)['"]\s*$/m);
  return importSpecifierMatch ? importSpecifierMatch[1] : null;
}
/**
 * parses an import specifier, looking for a web modules to install. If a web module is not detected,
 * null is returned.
 */


function parseWebModuleSpecifier(specifier) {
  if (!specifier) {
    return null;
  } // If specifier is a "bare module specifier" (ie: package name) just return it directly


  if (BARE_SPECIFIER_REGEX.test(specifier)) {
    return specifier;
  } // Clean the specifier, remove any query params that may mess with matching


  const cleanedSpecifier = removeSpecifierQueryString(specifier); // Otherwise, check that it includes the "web_modules/" directory

  const webModulesIndex = cleanedSpecifier.indexOf(WEB_MODULES_TOKEN);

  if (webModulesIndex === -1) {
    return null;
  } // Check if this matches `@scope/package.js` or `package.js` format.
  // If it is, assume that this is a top-level pcakage that should be installed without the “.js”


  const resolvedSpecifier = cleanedSpecifier.substring(webModulesIndex + WEB_MODULES_TOKEN_LENGTH);
  const resolvedSpecifierWithoutExtension = stripJsExtension(resolvedSpecifier);

  if (validatePackageName(resolvedSpecifierWithoutExtension).validForNewPackages) {
    return resolvedSpecifierWithoutExtension;
  } // Otherwise, this is an explicit import to a file within a package.


  return resolvedSpecifier;
}

function parseImportStatement(code, imp) {
  const webModuleSpecifier = parseWebModuleSpecifier(getWebModuleSpecifierFromCode(code, imp));

  if (!webModuleSpecifier) {
    return null;
  }

  const importStatement = code.substring(imp.ss, imp.se);

  if (/^import\s+type/.test(importStatement)) {
    return null;
  }

  const isDynamicImport = imp.d > -1;
  const hasDefaultImport = !isDynamicImport && DEFAULT_IMPORT_REGEX.test(importStatement);
  const hasNamespaceImport = !isDynamicImport && importStatement.includes('*');
  const namedImports = (importStatement.match(HAS_NAMED_IMPORTS_REGEX) || [, ''])[1].split(',') // split `import { a, b, c }` by comma
  .map(name => name.replace(STRIP_AS, '').trim()) // remove “ as …” and trim
  .filter(isTruthy);
  return {
    specifier: webModuleSpecifier,
    all: isDynamicImport || !hasDefaultImport && !hasNamespaceImport && namedImports.length === 0,
    default: hasDefaultImport,
    namespace: hasNamespaceImport,
    named: namedImports
  };
}

function cleanCodeForParsing(code) {
  code = stripComments(code);
  const allMatches = [];
  let match;
  const importRegex = new RegExp(ESM_IMPORT_REGEX);

  while (match = importRegex.exec(code)) {
    allMatches.push(match);
  }

  const dynamicImportRegex = new RegExp(ESM_DYNAMIC_IMPORT_REGEX);

  while (match = dynamicImportRegex.exec(code)) {
    allMatches.push(match);
  }

  return allMatches.map(([full]) => full).join('\n');
}

function parseCodeForInstallTargets({
  locOnDisk,
  baseExt,
  contents
}) {
  let imports; // Attempt #1: Parse the file as JavaScript. JSX and some decorator
  // syntax will break this.

  try {
    if (baseExt === '.jsx' || baseExt === '.tsx') {
      // We know ahead of time that this will almost certainly fail.
      // Just jump right to the secondary attempt.
      throw new Error('JSX must be cleaned before parsing');
    }

    [imports] = esModuleLexer.parse(contents) || [];
  } catch (err) {
    // Attempt #2: Parse only the import statements themselves.
    // This lets us guarentee we aren't sending any broken syntax to our parser,
    // but at the expense of possible false +/- caused by our regex extractor.
    try {
      contents = cleanCodeForParsing(contents);
      [imports] = esModuleLexer.parse(contents) || [];
    } catch (err) {
      // Another error! No hope left, just abort.
      console.error(colors.red(`! ${locOnDisk}`));
      throw err;
    }
  }

  const allImports = imports.map(imp => parseImportStatement(contents, imp)).filter(isTruthy) // Babel macros are not install targets!
  .filter(imp => !/[./]macro(\.js)?$/.test(imp.specifier));
  return allImports;
}

function scanDepList(depList, cwd) {
  return depList.map(whitelistItem => {
    if (!glob.hasMagic(whitelistItem)) {
      return [createInstallTarget(whitelistItem, true)];
    } else {
      const nodeModulesLoc = path.join(cwd, 'node_modules');
      return scanDepList(glob.sync(whitelistItem, {
        cwd: nodeModulesLoc,
        nodir: true
      }), cwd);
    }
  }).reduce((flat, item) => flat.concat(item), []);
}
async function scanImports(cwd, config) {
  await esModuleLexer.init;
  const includeFileSets = await Promise.all(Object.keys(config.mount).map(fromDisk => {
    const dirDisk = path.resolve(cwd, fromDisk);
    return glob.sync(`**/*`, {
      ignore: config.exclude.concat(['**/web_modules/**/*']),
      cwd: dirDisk,
      absolute: true,
      nodir: true
    });
  }));
  const includeFiles = Array.from(new Set([].concat.apply([], includeFileSets)));

  if (includeFiles.length === 0) {
    return [];
  } // Scan every matched JS file for web dependency imports


  const loadedFiles = await Promise.all(includeFiles.map(async filePath => {
    const {
      baseExt,
      expandedExt
    } = getExt(filePath); // Always ignore dotfiles

    if (filePath.startsWith('.')) {
      return null;
    }

    switch (baseExt) {
      // Probably a license, a README, etc
      case '':
        {
          return null;
        }
      // Our import scanner can handle normal JS & even TypeScript without a problem.

      case '.js':
      case '.jsx':
      case '.mjs':
      case '.ts':
      case '.tsx':
        {
          return {
            baseExt,
            expandedExt,
            locOnDisk: filePath,
            contents: await fs__default.promises.readFile(filePath, 'utf-8')
          };
        }

      case '.html':
      case '.vue':
      case '.svelte':
        {
          const result = await fs__default.promises.readFile(filePath, 'utf-8'); // TODO: Replace with matchAll once Node v10 is out of TLS.
          // const allMatches = [...result.matchAll(new RegExp(HTML_JS_REGEX))];

          const allMatches = [];
          let match;
          const regex = new RegExp(HTML_JS_REGEX);

          while (match = regex.exec(result)) {
            allMatches.push(match);
          }

          return {
            baseExt,
            expandedExt,
            locOnDisk: filePath,
            // match[2] is the code inside the <script></script> element
            contents: allMatches.map(match => match[2]).filter(s => s.trim()).join('\n')
          };
        }
    } // If we don't recognize the file type, it could be source. Warn just in case.


    if (!mime.lookup(baseExt)) {
      console.warn(colors.dim(`ignoring unsupported file "${path.relative(process.cwd(), filePath)}"`));
    }

    return null;
  }));
  return scanImportsFromFiles(loadedFiles.filter(isTruthy), config);
}
async function scanImportsFromFiles(loadedFiles, config) {
  return loadedFiles.map(parseCodeForInstallTargets).reduce((flat, item) => flat.concat(item), []).filter(target => {
    const aliasEntry = findMatchingAliasEntry(config, target.specifier);
    return !aliasEntry || aliasEntry.type === 'package';
  }).sort((impA, impB) => impA.specifier.localeCompare(impB.specifier));
}

/** The minimum width, in characters, of each size column */

const SIZE_COLUMN_WIDTH = 11;
/** Generic Object.entries() alphabetical sort by keys. */

function entriesSort([filenameA], [filenameB]) {
  return filenameA.localeCompare(filenameB);
}
/** Pretty-prints number of bytes as "XXX KB" */


function formatSize(size) {
  let kb = Math.round(size / 1000 * 100) / 100;

  if (kb >= 1000) {
    kb = Math.floor(kb);
  }

  let color;

  if (kb < 15) {
    color = 'green';
  } else if (kb < 30) {
    color = 'yellow';
  } else {
    color = 'red';
  }

  return colors[color](`${kb} KB`.padEnd(SIZE_COLUMN_WIDTH));
}

function formatDelta(delta) {
  const kb = Math.round(delta * 100) / 100;
  const color = delta > 0 ? 'red' : 'green';
  return colors[color](`Δ ${delta > 0 ? '+' : ''}${kb} KB`);
}

function formatFileInfo(filename, stats, padEnd, isLastFile) {
  const lineGlyph = colors.dim(isLastFile ? '└─' : '├─');
  const lineName = filename.padEnd(padEnd);
  const fileStat = formatSize(stats.size);
  const gzipStat = formatSize(stats.gzip);
  const brotliStat = formatSize(stats.brotli);
  const lineStat = fileStat + gzipStat + brotliStat;
  let lineDelta = '';

  if (stats.delta) {
    lineDelta = colors.dim('[') + formatDelta(stats.delta) + colors.dim(']');
  } // Trim trailing whitespace (can mess with formatting), but keep indentation.


  return `    ` + `${lineGlyph} ${lineName} ${lineStat} ${lineDelta}`.trim();
}

function formatFiles(files, padEnd) {
  const strippedFiles = files.map(([filename, stats]) => [filename.replace(/^common\//, ''), stats]);
  return strippedFiles.map(([filename, stats], index) => formatFileInfo(filename, stats, padEnd, index >= files.length - 1)).join('\n');
}

function printStats(dependencyStats) {
  let output = '';
  const {
    direct,
    common
  } = dependencyStats;
  const allDirect = Object.entries(direct).sort(entriesSort);
  const allCommon = Object.entries(common).sort(entriesSort);
  const maxFileNameLength = [...allCommon, ...allDirect].reduce((max, [filename]) => Math.max(filename.length, max), 'web_modules/'.length) + 1;
  output += `  ⦿ ${colors.bold('web_modules/'.padEnd(maxFileNameLength + 4))}` + colors.bold(colors.underline('size'.padEnd(SIZE_COLUMN_WIDTH - 2))) + '  ' + colors.bold(colors.underline('gzip'.padEnd(SIZE_COLUMN_WIDTH - 2))) + '  ' + colors.bold(colors.underline('brotli'.padEnd(SIZE_COLUMN_WIDTH - 2))) + `\n`;
  output += `${formatFiles(allDirect, maxFileNameLength)}\n`;

  if (Object.values(common).length > 0) {
    output += `  ⦿ ${colors.bold('web_modules/common/ (Shared)')}\n`;
    output += `${formatFiles(allCommon, maxFileNameLength)}\n`;
  }

  return `\n${output}\n`;
}

class ErrorWithHint extends Error {
  constructor(message, hint) {
    super(message);
    this.hint = hint;
  }

} // Add popular CJS packages here that use "synthetic" named imports in their documentation.
// CJS packages should really only be imported via the default export:
//   import React from 'react';
// But, some large projects use named exports in their documentation:
//   import {useState} from 'react';
//
// We use "/index.js here to match the official package, but not any ESM aliase packages
// that the user may have installed instead (ex: react-esm).


const CJS_PACKAGES_TO_AUTO_DETECT = ['react/index.js', 'react-dom/index.js', 'react-dom/server.js', 'react-is/index.js', 'prop-types/index.js', 'scheduler/index.js', 'react-table'];
const cwd = process.cwd();
const banner = colors.bold(`snowpack`) + ` installing... `;
let spinner;
let spinnerHasError = false;
let installResults = [];
let dependencyStats = null;

function defaultLogError(msg) {
  if (spinner && !spinnerHasError) {
    spinner.stopAndPersist({
      symbol: colors.cyan('⠼')
    });
  }

  spinnerHasError = true;
  spinner = ora(colors.red(msg));
  spinner.fail();
}

function defaultLogUpdate(msg) {
  spinner.text = banner + msg;
}

function formatInstallResults() {
  return installResults.map(([d, result]) => {
    if (result === 'SUCCESS') {
      return colors.green(d);
    }

    if (result === 'ASSET') {
      return colors.yellow(d);
    }

    if (result === 'FAIL') {
      return colors.red(d);
    }

    return d;
  }).join(', ');
}

function isImportOfPackage(importUrl, packageName) {
  return packageName === importUrl || importUrl.startsWith(packageName + '/');
}
/**
 * Formats the snowpack dependency name from a "webDependencies" input value:
 * 2. Remove any ".js"/".mjs" extension (will be added automatically by Rollup)
 */


function getWebDependencyName(dep) {
  return validatePackageName(dep).validForNewPackages ? dep.replace(/\.js$/i, 'js') // if this is a top-level package ending in .js, replace with js (e.g. tippy.js -> tippyjs)
  : dep.replace(/\.m?js$/i, ''); // otherwise simply strip the extension (Rollup will resolve it)
}
/**
 * Takes object of env var mappings and converts it to actual
 * replacement specs as expected by @rollup/plugin-replace. The
 * `optimize` arg is used to derive NODE_ENV default.
 *
 * @param env
 * @param optimize
 */


function getRollupReplaceKeys(env) {
  const result = Object.keys(env).reduce((acc, id) => {
    const val = env[id];
    acc[`process.env.${id}`] = `${JSON.stringify(val === true ? process.env[id] : val)}`;
    return acc;
  }, {
    'process.env.NODE_ENV': JSON.stringify(process.env.NODE_ENV || 'production'),
    'process.versions.node': 'undefined',
    'process.platform': JSON.stringify('browser'),
    'process.env.': '({}).',
    'typeof process.versions.node': JSON.stringify('undefined'),
    'typeof process.versions': JSON.stringify('undefined'),
    'typeof process': JSON.stringify('undefined')
  });
  return result;
}
/**
 * Resolve a "webDependencies" input value to the correct absolute file location.
 * Supports both npm package names, and file paths relative to the node_modules directory.
 * Follows logic similar to Node's resolution logic, but using a package.json's ESM "module"
 * field instead of the CJS "main" field.
 */


function resolveWebDependency(dep) {
  // if dep points directly to a file within a package, return that reference.
  // No other lookup required.
  if (path.extname(dep) && !validatePackageName(dep).validForNewPackages) {
    const isJSFile = ['.js', '.mjs', '.cjs'].includes(path.extname(dep));
    return {
      type: isJSFile ? 'JS' : 'ASSET',
      loc: require.resolve(dep, {
        paths: [cwd]
      })
    };
  } // If dep is a path within a package (but without an extension), we first need
  // to check for an export map in the package.json. If one exists, resolve to it.


  const [packageName, packageEntrypoint] = parsePackageImportSpecifier(dep);

  if (packageEntrypoint) {
    const [packageManifestLoc, packageManifest] = resolveDependencyManifest(packageName, cwd);

    if (packageManifestLoc && packageManifest && packageManifest.exports) {
      const exportMapEntry = packageManifest.exports['./' + packageEntrypoint];
      const exportMapValue = (exportMapEntry === null || exportMapEntry === void 0 ? void 0 : exportMapEntry.browser) || (exportMapEntry === null || exportMapEntry === void 0 ? void 0 : exportMapEntry.import) || (exportMapEntry === null || exportMapEntry === void 0 ? void 0 : exportMapEntry.default) || (exportMapEntry === null || exportMapEntry === void 0 ? void 0 : exportMapEntry.require) || exportMapEntry;

      if (typeof exportMapValue !== 'string') {
        throw new Error(`Package "${packageName}" exists but package.json "exports" does not include entry for "./${packageEntrypoint}".`);
      }

      return {
        type: 'JS',
        loc: path.join(packageManifestLoc, '..', exportMapValue)
      };
    }
  } // Otherwise, resolve directly to the dep specifier. Note that this supports both
  // "package-name" & "package-name/some/path" where "package-name/some/path/package.json"
  // exists at that lower path, that must be used to resolve. In that case, export
  // maps should not be supported.


  const [depManifestLoc, depManifest] = resolveDependencyManifest(dep, cwd);

  if (!depManifest) {
    try {
      const maybeLoc = require.resolve(dep, {
        paths: [cwd]
      });

      return {
        type: 'JS',
        loc: maybeLoc
      };
    } catch (err) {// Oh well, was worth a try
    }
  }

  if (!depManifestLoc || !depManifest) {
    throw new ErrorWithHint(`Package "${dep}" not found. Have you installed it?`, depManifestLoc ? colors.italic(depManifestLoc) : '');
  }

  if (depManifest.name && (depManifest.name.startsWith('@reactesm') || depManifest.name.startsWith('@pika/react'))) {
    throw new Error(`React workaround packages no longer needed! Revert back to the official React & React-DOM packages.`);
  }

  let foundEntrypoint = depManifest['browser:module'] || depManifest.module || depManifest['main:esnext'] || depManifest.browser; // Some packages define "browser" as an object. We'll do our best to find the
  // right entrypoint in an entrypoint object, or fail otherwise.
  // See: https://github.com/defunctzombie/package-browser-field-spec

  if (typeof foundEntrypoint === 'object') {
    foundEntrypoint = foundEntrypoint[dep] || foundEntrypoint['./index.js'] || foundEntrypoint['./index'] || foundEntrypoint['./'] || foundEntrypoint['.'];
  } // If browser object is set but no relevant entrypoint is found, fall back to "main".


  if (!foundEntrypoint) {
    foundEntrypoint = depManifest.main;
  } // Sometimes packages don't give an entrypoint, assuming you'll fall back to "index.js".


  const isImplicitEntrypoint = !foundEntrypoint;

  if (isImplicitEntrypoint) {
    foundEntrypoint = 'index.js';
  }

  if (typeof foundEntrypoint !== 'string') {
    throw new Error(`"${dep}" has unexpected entrypoint: ${JSON.stringify(foundEntrypoint)}.`);
  }

  try {
    return {
      type: 'JS',
      loc: require.resolve(path.join(depManifestLoc || '', '..', foundEntrypoint))
    };
  } catch (err) {
    // Type only packages! Some packages are purely for TypeScript (ex: csstypes).
    // If no JS entrypoint was given or found, but a TS "types"/"typings" entrypoint
    // was given, assume a TS-types only package and ignore.
    if (isImplicitEntrypoint && (depManifest.types || depManifest.typings)) {
      return {
        type: 'IGNORE',
        loc: ''
      };
    } // Otherwise, file truly doesn't exist.


    throw err;
  }
}

const FAILED_INSTALL_RETURN = {
  success: false,
  importMap: null
};
async function install(installTargets, {
  lockfile,
  logError,
  logUpdate
}, config) {
  const {
    webDependencies,
    alias: installAlias,
    installOptions: {
      installTypes,
      dest: destLoc,
      externalPackage: externalPackages,
      sourceMap,
      env,
      rollup: userDefinedRollup,
      treeshake: isTreeshake
    }
  } = config;
  const nodeModulesInstalled = findUp.sync('node_modules', {
    cwd,
    type: 'directory'
  });

  if (!webDependencies && !process.versions.pnp && !nodeModulesInstalled) {
    logError('no "node_modules" directory exists. Did you run "npm install" first?');
    return FAILED_INSTALL_RETURN;
  }

  const allInstallSpecifiers = new Set(installTargets.filter(dep => !externalPackages.some(packageName => isImportOfPackage(dep.specifier, packageName))).map(dep => dep.specifier).map(specifier => {
    const aliasEntry = findMatchingAliasEntry(config, specifier);
    return aliasEntry && aliasEntry.type === 'package' ? aliasEntry.to : specifier;
  }).sort());
  const installEntrypoints = {};
  const assetEntrypoints = {};
  const importMap = {
    imports: {}
  };
  const installTargetsMap = {};
  const autoDetectNamedExports = [...CJS_PACKAGES_TO_AUTO_DETECT, ...config.installOptions.namedExports];

  for (const installSpecifier of allInstallSpecifiers) {
    const targetName = getWebDependencyName(installSpecifier);
    const proxiedName = sanitizePackageName(targetName); // sometimes we need to sanitize webModule names, as in the case of tippy.js -> tippyjs

    if (lockfile && lockfile.imports[installSpecifier]) {
      installEntrypoints[targetName] = lockfile.imports[installSpecifier];
      importMap.imports[installSpecifier] = `./${proxiedName}.js`;
      installResults.push([targetName, 'SUCCESS']);
      logUpdate(formatInstallResults());
      continue;
    }

    try {
      const {
        type: targetType,
        loc: targetLoc
      } = resolveWebDependency(installSpecifier);

      if (targetType === 'JS') {
        installEntrypoints[targetName] = targetLoc;
        importMap.imports[installSpecifier] = `./${proxiedName}.js`;
        Object.entries(installAlias).filter(([, value]) => value === installSpecifier).forEach(([key]) => {
          importMap.imports[key] = `./${targetName}.js`;
        });
        installTargetsMap[targetLoc] = installTargets.filter(t => installSpecifier === t.specifier);
        installResults.push([installSpecifier, 'SUCCESS']);
      } else if (targetType === 'ASSET') {
        assetEntrypoints[targetName] = targetLoc;
        importMap.imports[installSpecifier] = `./${proxiedName}`;
        installResults.push([installSpecifier, 'ASSET']);
      }

      logUpdate(formatInstallResults());
    } catch (err) {
      installResults.push([installSpecifier, 'FAIL']);
      logUpdate(formatInstallResults());


      logError(err.message || err);

      if (err.hint) {
        // Note: Wait 1ms to guarantee a log message after the spinner
        setTimeout(() => console.log(err.hint), 1);
      }

      return FAILED_INSTALL_RETURN;
    }
  }

  if (Object.keys(installEntrypoints).length === 0 && Object.keys(assetEntrypoints).length === 0) {
    logError(`No ESM dependencies found!`);
    console.log(colors.dim(`  At least one dependency must have an ESM "module" entrypoint. You can find modern, web-ready packages at ${colors.underline('https://www.pika.dev')}`));
    return FAILED_INSTALL_RETURN;
  }

  await esModuleLexer.init;
  let isCircularImportFound = false;
  const inputOptions = {
    input: installEntrypoints,
    external: id => externalPackages.some(packageName => isImportOfPackage(id, packageName)),
    treeshake: {
      moduleSideEffects: 'no-external'
    },
    plugins: [rollupPluginReplace(getRollupReplaceKeys(env)), !!webDependencies && rollupPluginDependencyCache({
      installTypes,
      log: url => logUpdate(colors.dim(url))
    }), rollupPluginAlias({
      entries: Object.entries(installAlias).filter(([, val]) => isPackageAliasEntry(val)).map(([key, val]) => ({
        find: key,
        replacement: val
      }))
    }), rollupPluginCatchFetch(), rollupPluginNodeResolve({
      mainFields: ['browser:module', 'module', 'browser', 'main'].filter(isTruthy),
      extensions: ['.mjs', '.cjs', '.js', '.json'],
      // whether to prefer built-in modules (e.g. `fs`, `path`) or local ones with the same names
      preferBuiltins: true,
      dedupe: userDefinedRollup.dedupe
    }), rollupPluginJson({
      preferConst: true,
      indent: '  ',
      compact: false,
      namedExports: true
    }), rollupPluginCss(), rollupPluginCommonjs({
      extensions: ['.js', '.cjs'],
      // Workaround: CJS -> ESM isn't supported yet by the plugin, so we needed
      // to add our own custom workaround here. Requires a fork of
      // rollupPluginCommonjs that supports the "externalEsm" option.
      externalEsm: process.env.EXTERNAL_ESM_PACKAGES || []
    }), rollupPluginWrapInstallTargets(!!isTreeshake, autoDetectNamedExports, installTargets), rollupPluginDependencyStats(info => dependencyStats = info), ...userDefinedRollup.plugins, rollupPluginCatchUnresolved()].filter(Boolean),

    onwarn(warning, warn) {
      // Warn about the first circular dependency, but then ignore the rest.
      if (warning.code === 'CIRCULAR_DEPENDENCY') {
        if (!isCircularImportFound) {
          isCircularImportFound = true;
          logUpdate(`Warning: 1+ circular dependencies found via "${warning.importer}".`);
        }

        return;
      } // Log "unresolved" import warnings as an error, causing Snowpack to fail at the end.


      if (warning.code === 'PLUGIN_WARNING' && warning.plugin === 'snowpack:rollup-plugin-catch-unresolved') {
        // Display posix-style on all environments, mainly to help with CI :)
        if (warning.id) {
          const fileName = path.relative(cwd, warning.id).replace(/\\/g, '/');
          logError(`${fileName}\n   ${warning.message}`);
        } else {
          logError(`${warning.message}. See https://www.snowpack.dev/#troubleshooting`);
        }

        return;
      }

      warn(warning);
    }

  };
  const outputOptions = {
    dir: destLoc,
    format: 'esm',
    sourcemap: sourceMap,
    exports: 'named',
    chunkFileNames: 'common/[name]-[hash].js'
  };

  if (Object.keys(installEntrypoints).length > 0) {
    try {
      const packageBundle = await rollup.rollup(inputOptions);
      logUpdate(formatInstallResults());
      await packageBundle.write(outputOptions);
    } catch (_err) {
      var _err$loc;

      const err = _err;
      const errFilePath = ((_err$loc = err.loc) === null || _err$loc === void 0 ? void 0 : _err$loc.file) || err.id;

      if (!errFilePath) {
        throw err;
      } // NOTE: Rollup will fail instantly on most errors. Therefore, we can
      // only report one error at a time. `err.watchFiles` also exists, but
      // for now `err.loc.file` and `err.id` have all the info that we need.


      const failedExtension = path.extname(errFilePath);
      const suggestion = MISSING_PLUGIN_SUGGESTIONS[failedExtension] || err.message; // Display posix-style on all environments, mainly to help with CI :)

      const fileName = path.relative(cwd, errFilePath).replace(/\\/g, '/');
      logError(`${colors.bold('snowpack')} failed to load ${colors.bold(fileName)}\n  ${suggestion}`);
      return FAILED_INSTALL_RETURN;
    }
  }

  await writeLockfile(path.join(destLoc, 'import-map.json'), importMap);

  for (const [assetName, assetLoc] of Object.entries(assetEntrypoints)) {
    const assetDest = `${destLoc}/${sanitizePackageName(assetName)}`;
    mkdirp.sync(path.dirname(assetDest));
    fs__default.copyFileSync(assetLoc, assetDest);
  }

  return {
    success: true,
    importMap
  };
}
async function getInstallTargets(config, scannedFiles) {
  const {
    knownEntrypoints,
    webDependencies
  } = config;
  const installTargets = [];

  if (knownEntrypoints) {
    installTargets.push(...scanDepList(knownEntrypoints, cwd));
  }

  if (webDependencies) {
    installTargets.push(...scanDepList(Object.keys(webDependencies), cwd));
  }

  if (scannedFiles) {
    installTargets.push(...(await scanImportsFromFiles(scannedFiles, config)));
  } else {
    installTargets.push(...(await scanImports(cwd, config)));
  }

  return installTargets;
}
async function command(commandOptions) {
  const {
    cwd,
    config
  } = commandOptions;
  const installTargets = await getInstallTargets(config);

  if (installTargets.length === 0) {
    defaultLogError('Nothing to install.');
    return;
  }

  const finalResult = await run(_objectSpread2(_objectSpread2({}, commandOptions), {}, {
    installTargets
  }));

  if (finalResult.newLockfile) {
    await writeLockfile(path.join(cwd, 'snowpack.lock.json'), finalResult.newLockfile);
  }

  if (finalResult.stats) {
    console.log(printStats(finalResult.stats));
  }

  if (!finalResult.success || finalResult.hasError) {
    process.exit(1);
  }
}
async function run({
  config,
  lockfile,
  installTargets
}) {
  const {
    installOptions: {
      dest
    },
    webDependencies
  } = config;
  installResults = [];
  dependencyStats = null;
  spinner = ora(banner);
  spinnerHasError = false;

  if (installTargets.length === 0) {
    return {
      success: true,
      hasError: false,
      importMap: {
        imports: {}
      },
      newLockfile: null,
      stats: null
    };
  }

  let newLockfile = null;

  if (webDependencies && Object.keys(webDependencies).length > 0) {
    newLockfile = await resolveTargetsFromRemoteCDN(lockfile, config).catch(err => {
      defaultLogError(err.message || err);
      process.exit(1);
    });
  }

  rimraf.sync(dest);
  const installStart = perf_hooks.performance.now();
  const finalResult = await install(installTargets, {
    lockfile: newLockfile,
    logError: defaultLogError,
    logUpdate: defaultLogUpdate
  }, config).catch(err => {
    if (err.loc) {
      console.log('\n' + colors.red(colors.bold(`✘ ${err.loc.file}`)));
    }

    if (err.url) {
      console.log(colors.dim(`👉 ${err.url}`));
    }

    spinner.stop();
    throw err;
  });

  if (finalResult.success) {
    const installEnd = perf_hooks.performance.now();
    spinner.succeed(colors.bold(`snowpack`) + ` install complete${spinnerHasError ? ' with errors.' : '.'}` + colors.dim(` [${((installEnd - installStart) / 1000).toFixed(2)}s]`));
  } else {
    spinner.stop();
  }

  return {
    success: finalResult.success,
    hasError: spinnerHasError,
    importMap: finalResult.importMap,
    newLockfile,
    stats: dependencyStats
  };
}

async function addCommand(addValue, commandOptions) {
  const {
    cwd,
    config,
    pkgManifest
  } = commandOptions;
  let [pkgName, pkgSemver] = addValue.split('@');

  if (!pkgSemver) {
    const body = await got(`http://registry.npmjs.org/${pkgName}/latest`).json();
    pkgSemver = `^${body.version}`;
  }

  pkgManifest.webDependencies = pkgManifest.webDependencies || {};
  pkgManifest.webDependencies[pkgName] = pkgSemver;
  config.webDependencies = config.webDependencies || {};
  config.webDependencies[pkgName] = pkgSemver;
  await fs.promises.writeFile(path.join(cwd, 'package.json'), JSON.stringify(pkgManifest, null, 2));
  await command(commandOptions);
}
async function rmCommand(addValue, commandOptions) {
  const {
    cwd,
    config,
    pkgManifest
  } = commandOptions;
  let [pkgName] = addValue.split('@');
  pkgManifest.webDependencies = pkgManifest.webDependencies || {};
  delete pkgManifest.webDependencies[pkgName];
  config.webDependencies = config.webDependencies || {};
  delete config.webDependencies[pkgName];
  await fs.promises.writeFile(path.join(cwd, 'package.json'), JSON.stringify(pkgManifest, null, 2));
  await command(commandOptions);
}

function getMetaUrlPath(urlPath, isDev, config) {
  let {
    baseUrl,
    metaDir
  } = config.buildOptions || {};

  if (isDev) {
    return path.posix.normalize(path.posix.join('/', metaDir, urlPath));
  }

  if (URL_HAS_PROTOCOL_REGEX.test(baseUrl)) {
    return baseUrl + path.posix.normalize(path.posix.join(metaDir, urlPath));
  }

  return path.posix.normalize(path.posix.join(baseUrl, metaDir, urlPath));
}
function wrapImportMeta({
  code,
  hmr,
  env,
  isDev,
  config
}) {
  if (!code.includes('import.meta')) {
    return code;
  }

  return (hmr ? `import * as  __SNOWPACK_HMR__ from '${getMetaUrlPath('hmr.js', isDev, config)}';\nimport.meta.hot = __SNOWPACK_HMR__.createHotContext(import.meta.url);\n` : ``) + (env ? `import __SNOWPACK_ENV__ from '${getMetaUrlPath('env.js', isDev, config)}';\nimport.meta.env = __SNOWPACK_ENV__;\n` : ``) + '\n' + code;
}
function wrapHtmlResponse({
  code,
  isDev,
  hmr,
  config
}) {
  // replace %PUBLIC_URL% in HTML files (along with surrounding slashes, if any)
  code = code.replace(/\/?%PUBLIC_URL%\/?/g, config.buildOptions.baseUrl);

  if (hmr) {
    code += `<script type="module" src="${getMetaUrlPath('hmr.js', isDev, config)}"></script>`;
  }

  return code;
}

function generateJsonImportProxy({
  code,
  hmr,
  isDev,
  config
}) {
  const jsonImportProxyCode = `${hmr ? `import.meta.hot.accept(({module}) => { json = module.default; });` : ''}
let json = ${JSON.stringify(JSON.parse(code))};
export default json;`;
  return wrapImportMeta({
    code: jsonImportProxyCode,
    hmr,
    env: false,
    isDev,
    config
  });
}

function generateCssImportProxy({
  code,
  hmr,
  isDev,
  config
}) {
  const cssImportProxyCode = `${hmr ? `
import.meta.hot.accept();
import.meta.hot.dispose(() => {
document.head.removeChild(styleEl);
});\n` : ''}
const code = ${JSON.stringify(code)};

const styleEl = document.createElement("style");
const codeEl = document.createTextNode(code);
styleEl.type = 'text/css';

styleEl.appendChild(codeEl);
document.head.appendChild(styleEl);`;
  return wrapImportMeta({
    code: cssImportProxyCode,
    hmr,
    env: false,
    isDev,
    config
  });
}

let _cssModuleLoader;

async function generateCssModuleImportProxy({
  url,
  code,
  isDev,
  hmr,
  config
}) {
  _cssModuleLoader = _cssModuleLoader || new (require('css-modules-loader-core'))();
  const {
    injectableSource,
    exportTokens
  } = await _cssModuleLoader.load(code, url, undefined, () => {
    throw new Error('Imports in CSS Modules are not yet supported.');
  });
  return `${hmr ? `
import * as __SNOWPACK_HMR_API__ from '${getMetaUrlPath('hmr.js', isDev, config)}';
import.meta.hot = __SNOWPACK_HMR_API__.createHotContext(import.meta.url);
import.meta.hot.accept(({module}) => {
  code = module.code;
  json = module.default;
});
import.meta.hot.dispose(() => {
  document.head.removeChild(styleEl);
});\n` : ``}
export let code = ${JSON.stringify(injectableSource)};
let json = ${JSON.stringify(exportTokens)};
export default json;

const styleEl = document.createElement("style");
const codeEl = document.createTextNode(code);
styleEl.type = 'text/css';

styleEl.appendChild(codeEl);
document.head.appendChild(styleEl);`;
}

function generateDefaultImportProxy(url) {
  return `export default ${JSON.stringify(url)};`;
}

async function wrapImportProxy({
  url,
  code,
  isDev,
  hmr,
  config
}) {
  const {
    baseExt,
    expandedExt
  } = getExt(url);

  if (baseExt === '.json') {
    return generateJsonImportProxy({
      code,
      hmr,
      isDev,
      config
    });
  }

  if (expandedExt.endsWith('.module.css')) {
    return await generateCssModuleImportProxy({
      url,
      code,
      isDev,
      hmr,
      config
    });
  }

  if (baseExt === '.css') {
    return generateCssImportProxy({
      code,
      hmr,
      isDev,
      config
    });
  }

  return generateDefaultImportProxy(url);
}
const PUBLIC_ENV_REGEX = /^SNOWPACK_PUBLIC_/;
function generateEnvModule(mode) {
  const envObject = _objectSpread2({}, process.env);

  for (const env of Object.keys(envObject)) {
    if (!PUBLIC_ENV_REGEX.test(env)) {
      delete envObject[env];
    }
  }

  envObject.MODE = mode;
  envObject.NODE_ENV = mode;
  return `export default ${JSON.stringify(envObject)};`;
}

var srcFileExtensionMapping = {
  '.mjs': '.js',
  '.jsx': '.js',
  '.ts': '.js',
  '.tsx': '.js',
  '.vue': '.js',
  '.svelte': '.js',
  '.mdx': '.js',
  '.svx': '.js',
  '.elm': '.js',
  '.yaml': '.json',
  '.toml': '.json',
  '.php': '.html',
  '.md': '.html',
  '.ejs': '.html',
  '.njk': '.html',
  '.scss': '.css',
  '.sass': '.css',
  '.less': '.css'
};

let esbuildService = null;
const IS_PREACT = /from\s+['"]preact['"]/;

function checkIsPreact(filePath, contents) {
  return filePath.endsWith('.jsx') && IS_PREACT.test(contents);
}

function getLoader(filePath) {
  const ext = path.extname(filePath);

  if (ext === '.mjs') {
    return 'js';
  }

  return ext.substr(1);
}

function esbuildPlugin(_, {
  input
}) {
  return {
    name: '@snowpack/plugin-esbuild',
    resolve: {
      input,
      output: ['.js']
    },

    async load({
      filePath
    }) {
      esbuildService = esbuildService || (await esbuild.startService());
      const contents = await fs.promises.readFile(filePath, 'utf-8');
      const isPreact = checkIsPreact(filePath, contents);
      const {
        js,
        warnings
      } = await esbuildService.transform(contents, {
        loader: getLoader(filePath),
        jsxFactory: isPreact ? 'h' : undefined,
        jsxFragment: isPreact ? 'Fragment' : undefined
      });

      for (const warning of warnings) {
        console.error(colors.bold('! ') + filePath);
        console.error('  ' + warning.text);
      }

      return {
        '.js': js || ''
      };
    }

  };
}
function stopEsbuild() {
  esbuildService && esbuildService.stop();
}

const CONFIG_NAME = 'snowpack';
const ALWAYS_EXCLUDE = ['**/node_modules/**/*', '**/.types/**/*']; // default settings

const DEFAULT_CONFIG = {
  exclude: ['__tests__/**/*', '**/*.@(spec|test).*'],
  plugins: [],
  alias: {},
  installOptions: {
    dest: 'web_modules',
    externalPackage: [],
    installTypes: false,
    env: {},
    namedExports: [],
    rollup: {
      plugins: [],
      dedupe: []
    }
  },
  scripts: {},
  devOptions: {
    secure: false,
    hostname: 'localhost',
    port: 8080,
    open: 'default',
    out: 'build',
    fallback: 'index.html',
    hmr: true
  },
  buildOptions: {
    baseUrl: '/',
    webModulesUrl: '/web_modules',
    clean: false,
    metaDir: '__snowpack__',
    minify: true
  }
};
const configSchema = {
  type: 'object',
  properties: {
    extends: {
      type: 'string'
    },
    install: {
      type: 'array',
      items: {
        type: 'string'
      }
    },
    exclude: {
      type: 'array',
      items: {
        type: 'string'
      }
    },
    plugins: {
      type: 'array'
    },
    webDependencies: {
      type: ['object'],
      additionalProperties: {
        type: 'string'
      }
    },
    scripts: {
      type: ['object'],
      additionalProperties: {
        type: 'string'
      }
    },
    alias: {
      type: 'object',
      additionalProperties: {
        type: 'string'
      }
    },
    devOptions: {
      type: 'object',
      properties: {
        secure: {
          type: 'boolean'
        },
        port: {
          type: 'number'
        },
        out: {
          type: 'string'
        },
        fallback: {
          type: 'string'
        },
        bundle: {
          type: 'boolean'
        },
        open: {
          type: 'string'
        },
        hmr: {
          type: 'boolean'
        }
      }
    },
    installOptions: {
      type: 'object',
      properties: {
        dest: {
          type: 'string'
        },
        externalPackage: {
          type: 'array',
          items: {
            type: 'string'
          }
        },
        treeshake: {
          type: 'boolean'
        },
        installTypes: {
          type: 'boolean'
        },
        sourceMap: {
          oneOf: [{
            type: 'boolean'
          }, {
            type: 'string'
          }]
        },
        alias: {
          type: 'object',
          additionalProperties: {
            type: 'string'
          }
        },
        env: {
          type: 'object',
          additionalProperties: {
            oneOf: [{
              id: 'EnvVarString',
              type: 'string'
            }, {
              id: 'EnvVarNumber',
              type: 'number'
            }, {
              id: 'EnvVarTrue',
              type: 'boolean',
              enum: [true]
            }]
          }
        },
        rollup: {
          type: 'object',
          properties: {
            plugins: {
              type: 'array',
              items: {
                type: 'object'
              }
            },
            dedupe: {
              type: 'array',
              items: {
                type: 'string'
              }
            }
          }
        }
      }
    },
    buildOptions: {
      type: ['object'],
      properties: {
        baseUrl: {
          type: 'string'
        },
        clean: {
          type: 'boolean'
        },
        metaDir: {
          type: 'string'
        },
        minify: {
          type: 'boolean'
        }
      }
    },
    proxy: {
      type: 'object'
    }
  }
};
/**
 * Convert CLI flags to an incomplete Snowpack config representation.
 * We need to be careful about setting properties here if the flag value
 * is undefined, since the deep merge strategy would then overwrite good
 * defaults with 'undefined'.
 */

function expandCliFlags(flags) {
  const result = {
    installOptions: {},
    devOptions: {},
    buildOptions: {}
  };

  const relevantFlags = _objectWithoutProperties(flags, ["help", "version", "reload", "config"]);

  for (const [flag, val] of Object.entries(relevantFlags)) {
    if (flag === '_' || flag.includes('-')) {
      continue;
    }

    if (configSchema.properties[flag]) {
      result[flag] = val;
      continue;
    }

    if (configSchema.properties.installOptions.properties[flag]) {
      result.installOptions[flag] = val;
      continue;
    }

    if (configSchema.properties.devOptions.properties[flag]) {
      result.devOptions[flag] = val;
      continue;
    }

    if (configSchema.properties.buildOptions.properties[flag]) {
      result.buildOptions[flag] = val;
      continue;
    }

    console.error(`Unknown CLI flag: "${flag}"`);
    process.exit(1);
  }

  if (result.installOptions.env) {
    result.installOptions.env = result.installOptions.env.reduce((acc, id) => {
      const index = id.indexOf('=');
      const [key, val] = index > 0 ? [id.substr(0, index), id.substr(index + 1)] : [id, true];
      acc[key] = val;
      return acc;
    }, {});
  }

  return result;
}
/** ensure extensions all have preceding dots */


function parseScript(script) {
  const [scriptType, extMatch] = script.toLowerCase().split(':');
  const [inputMatch, outputMatch] = extMatch ? extMatch.split('->') : [];
  const cleanInput = [...new Set(inputMatch.split(',').map(ext => `.${ext}`))];
  let cleanOutput = [];

  if (outputMatch) {
    cleanOutput = [...new Set(outputMatch.split(',').map(ext => `.${ext}`))];
  } else if (cleanInput[0] === '.svelte') {
    cleanOutput = ['.js', '.css'];
  } else if (cleanInput[0] === '.vue') {
    cleanOutput = ['.js', '.css'];
  } else if (cleanInput.length > 0) {
    cleanOutput = Array.from(new Set(cleanInput.map(ext => srcFileExtensionMapping[ext] || ext)));
  }

  return {
    scriptType,
    input: cleanInput,
    output: cleanOutput
  };
}
/** load and normalize plugins from config */


function loadPlugins(config) {
  const plugins = [];

  function loadPluginFromScript(specifier) {
    try {
      const pluginLoc = require.resolve(specifier, {
        paths: [process.cwd()]
      });

      return require(pluginLoc)(config); // no plugin options to load because we’re loading from a string
    } catch (err) {// ignore
    }
  }

  function loadPluginFromConfig(name, options) {
    const pluginLoc = require.resolve(name, {
      paths: [process.cwd()]
    });

    const pluginRef = require(pluginLoc);

    let plugin;

    try {
      plugin = pluginRef.default ? pluginRef.default(config, options) : pluginRef(config, options);
    } catch (err) {
      console.error(`[${name}] ${err}`);
      throw err;
    }

    plugin.name = plugin.name || name; // Legacy support: Map the new load() interface to the old build() interface

    const {
      build,
      bundle
    } = plugin;

    if (build) {
      plugin.load = async options => {
        const result = await build(_objectSpread2(_objectSpread2({}, options), {}, {
          contents: fs__default.readFileSync(options.filePath, 'utf-8')
        })).catch(err => {
          console.error(`[${plugin.name}] ERROR: There was a problem running this older plugin. Please update the plugin to the latest version.`);
          throw err;
        });

        if (!result) {
          return null;
        }

        if (result.resources) {
          return {
            '.js': result.result,
            '.css': result.resources.css
          };
        }

        return result.result;
      };
    } // Legacy support: Map the new optimize() interface to the old bundle() interface


    if (bundle) {
      plugin.optimize = async options => {
        return bundle({
          srcDirectory: options.buildDirectory,
          destDirectory: options.buildDirectory,
          // @ts-ignore internal API only
          log: options.log,
          // It turns out, this was more or less broken (included all files, not just JS).
          // Confirmed no plugins are using this now, so safe to use an empty array.
          jsFilePaths: []
        }).catch(err => {
          console.error(`[${plugin.name}] ERROR: There was a problem running this older plugin. Please update the plugin to the latest version.`);
          throw err;
        });
      };
    }

    if (!plugin.resolve && plugin.defaultBuildScript && plugin.defaultBuildScript.startsWith('build:')) {
      const {
        input,
        output
      } = parseScript(plugin.defaultBuildScript);
      plugin.resolve = {
        input,
        output
      };
    } else if (plugin.resolve) {
      const {
        input,
        output
      } = plugin.resolve;
      plugin.resolve = {
        input,
        output
      };
    }

    validatePlugin(plugin);
    return plugin;
  } // 1. require & load config.scripts
  // TODO: deprecate scripts and move out of this function


  Object.entries(config.scripts).forEach(([target, cmd]) => {
    const {
      scriptType,
      input,
      output
    } = parseScript(target);

    if (config.plugins.some(p => (Array.isArray(p) ? p[0] : p) === cmd)) {
      handleConfigError(`[${name}]: loaded in both \`scripts\` and \`plugins\`. Please choose one (preferably \`plugins\`).`);
    }

    switch (scriptType) {
      case 'run':
        {
          if (target.endsWith('::watch')) {
            break;
          }

          const watchCmd = config.scripts[target + '::watch'];
          plugins.push(runScriptPlugin(config, {
            cmd,
            watch: watchCmd || cmd
          }));
          break;
        }

      case 'build':
        {
          plugins.push(buildScriptPlugin(config, {
            input,
            output,
            cmd
          }));
          break;
        }

      case 'bundle':
        {
          plugins.push(loadPluginFromScript(cmd));
          break;
        }
    }
  }); // 2. config.plugins

  config.plugins.forEach(ref => {
    const pluginName = Array.isArray(ref) ? ref[0] : ref;
    const pluginOptions = Array.isArray(ref) ? ref[1] : {};
    const plugin = loadPluginFromConfig(pluginName, pluginOptions);
    plugins.push(plugin);
  });
  const needsDefaultPlugin = new Set(['.mjs', '.jsx', '.ts', '.tsx']);
  plugins.filter(({
    resolve
  }) => !!resolve).reduce((arr, a) => arr.concat(a.resolve.input), []).forEach(ext => needsDefaultPlugin.delete(ext));

  if (needsDefaultPlugin.size > 0) {
    plugins.unshift(esbuildPlugin(config, {
      input: [...needsDefaultPlugin]
    }));
  }

  const extensionMap = plugins.reduce((map, {
    resolve
  }) => {
    if (resolve) {
      for (const inputExt of resolve.input) {
        map[inputExt] = resolve.output[0];
      }
    }

    return map;
  }, {});
  return {
    plugins,
    extensionMap
  };
}
/**
 * Convert deprecated proxy scripts to
 * FUTURE: Remove this on next major release
 */


function handleLegacyProxyScripts(config) {
  for (const scriptId in config.scripts) {
    if (!scriptId.startsWith('proxy:')) {
      continue;
    }

    const cmdArr = config.scripts[scriptId].split(/\s+/);

    if (cmdArr[0] !== 'proxy') {
      handleConfigError(`scripts[${scriptId}] must use the proxy command`);
    }

    cmdArr.shift();
    const {
      to,
      _
    } = yargs(cmdArr);

    if (_.length !== 1) {
      handleConfigError(`scripts[${scriptId}] must use the format: "proxy http://SOME.URL --to /PATH"`);
    }

    if (to && to[0] !== '/') {
      handleConfigError(`scripts[${scriptId}]: "--to ${to}" must be a URL path, and start with a "/"`);
    }

    const {
      toUrl,
      fromUrl
    } = {
      fromUrl: _[0],
      toUrl: to
    };

    if (config.proxy[toUrl]) {
      handleConfigError(`scripts[${scriptId}]: Cannot overwrite proxy[${toUrl}].`);
    }

    config.proxy[toUrl] = fromUrl;
    delete config.scripts[scriptId];
  }

  return config;
}

function normalizeProxies(proxies) {
  return Object.entries(proxies).map(([pathPrefix, options]) => {
    if (typeof options !== 'string') {
      return [pathPrefix, _objectSpread2({
        //@ts-ignore - Seems to be a strange 3.9.x bug
        on: {}
      }, options)];
    }

    return [pathPrefix, {
      on: {
        proxyReq: (proxyReq, req) => {
          const proxyPath = proxyReq.path.split(req.url)[0];
          proxyReq.path = proxyPath + req.url.replace(pathPrefix, '');
        }
      },
      target: options,
      changeOrigin: true,
      secure: false
    }];
  });
}

function normalizeMount(config) {
  const mountedDirs = config.mount || {};

  for (const [target, cmd] of Object.entries(config.scripts)) {
    if (target.startsWith('mount:')) {
      const cmdArr = cmd.split(/\s+/);

      if (cmdArr[0] !== 'mount') {
        handleConfigError(`scripts[${target}] must use the mount command`);
      }

      cmdArr.shift();
      const {
        to,
        _
      } = yargs(cmdArr);

      if (_.length !== 1) {
        handleConfigError(`scripts[${target}] must use the format: "mount dir [--to /PATH]"`);
      }

      if (target === 'mount:web_modules') {
        config.buildOptions.webModulesUrl = to;
      } else {
        mountedDirs[cmdArr[0]] = to || `/${cmdArr[0]}`;
      }
    }
  }

  for (const [mountDir, mountUrl] of Object.entries(mountedDirs)) {
    const fromDisk = path.posix.normalize(mountDir + '/');
    delete mountedDirs[mountDir];
    mountedDirs[fromDisk] = mountUrl;

    if (mountUrl[0] !== '/') {
      handleConfigError(`mount[${mountDir}]: Value "${mountUrl}" must be a URL path, and start with a "/"`);
    }
  } // if no mounted directories, mount the root directory to the base URL


  if (!Object.keys(mountedDirs).length) {
    mountedDirs['.'] = '/';
  }

  return mountedDirs;
}

function normalizeAlias(config, createMountAlias) {
  const cwd = process.cwd();
  const cleanAlias = config.alias || {};

  if (createMountAlias) {
    for (const mountDir of Object.keys(config.mount)) {
      if (mountDir !== '.') {
        cleanAlias[removeTrailingSlash(mountDir)] = `./${mountDir}`;
      }
    }
  }

  for (const [target, replacement] of Object.entries(config.alias)) {
    if (replacement.startsWith('./') || replacement.startsWith('../') || replacement.startsWith('/')) {
      cleanAlias[target] = path.resolve(cwd, replacement);
    }
  }

  return cleanAlias;
}
/** resolve --dest relative to cwd, etc. */


function normalizeConfig(config) {
  const cwd = process.cwd();
  config.knownEntrypoints = config.install || [];
  config.installOptions.dest = path.resolve(cwd, config.installOptions.dest);
  config.devOptions.out = path.resolve(cwd, config.devOptions.out);
  config.exclude = Array.from(new Set([...ALWAYS_EXCLUDE, ...config.exclude]));

  if (!config.proxy) {
    config.proxy = {};
  } // normalize config URL/path values


  config.buildOptions.baseUrl = addTrailingSlash(config.buildOptions.baseUrl);
  config.buildOptions.webModulesUrl = addLeadingSlash(config.buildOptions.webModulesUrl);
  config.buildOptions.metaDir = removeLeadingSlash(removeTrailingSlash(config.buildOptions.metaDir));
  const isLegacyMountConfig = !config.mount;
  config = handleLegacyProxyScripts(config);
  config.proxy = normalizeProxies(config.proxy);
  config.mount = normalizeMount(config);
  config.alias = normalizeAlias(config, isLegacyMountConfig); // new pipeline

  const {
    plugins,
    extensionMap
  } = loadPlugins(config);
  config.plugins = plugins;
  config._extensionMap = extensionMap; // If any plugins defined knownEntrypoints, add them here

  for (const {
    knownEntrypoints
  } of config.plugins) {
    if (knownEntrypoints) {
      config.knownEntrypoints = config.knownEntrypoints.concat(knownEntrypoints);
    }
  }

  return config;
}

function handleConfigError(msg) {
  console.error(`[error]: ${msg}`);
  process.exit(1);
}

function handleValidationErrors(filepath, errors) {
  console.error(colors.red(`! ${filepath || 'Configuration error'}`));
  console.error(errors.map(err => `    - ${err.toString()}`).join('\n'));
  console.error(`    See https://www.snowpack.dev/#configuration for more info.`);
  process.exit(1);
}

function handleDeprecatedConfigError(mainMsg, ...msgs) {
  console.error(colors.red(mainMsg));
  msgs.forEach(console.error);
  console.error(`See https://www.snowpack.dev/#configuration for more info.`);
  process.exit(1);
}

function validateConfigAgainstV1(rawConfig, cliFlags) {
  var _rawConfig$installOpt, _rawConfig$installOpt2, _rawConfig$installOpt3, _rawConfig$installOpt4, _rawConfig$devOptions, _rawConfig$installOpt5, _rawConfig$installOpt6, _rawConfig$installOpt7, _rawConfig$installOpt8, _rawConfig$installOpt9, _rawConfig$installOpt10;

  // Moved!
  if (rawConfig.dedupe || cliFlags.dedupe) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `dedupe` is now `installOptions.rollup.dedupe`.');
  }

  if (rawConfig.namedExports) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `rollup.namedExports` is no longer required. See also: installOptions.namedExports');
  }

  if ((_rawConfig$installOpt = rawConfig.installOptions) === null || _rawConfig$installOpt === void 0 ? void 0 : (_rawConfig$installOpt2 = _rawConfig$installOpt.rollup) === null || _rawConfig$installOpt2 === void 0 ? void 0 : _rawConfig$installOpt2.namedExports) {
    delete rawConfig.installOptions.rollup.namedExports;
    console.error(colors.yellow('[Snowpack v2.3.0] `rollup.namedExports` is no longer required. See also: installOptions.namedExports'));
  }

  if (rawConfig.rollup) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] top-level `rollup` config is now `installOptions.rollup`.');
  }

  if (((_rawConfig$installOpt3 = rawConfig.installOptions) === null || _rawConfig$installOpt3 === void 0 ? void 0 : _rawConfig$installOpt3.include) || cliFlags.include) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `installOptions.include` is now handled via "mount" build scripts!');
  }

  if ((_rawConfig$installOpt4 = rawConfig.installOptions) === null || _rawConfig$installOpt4 === void 0 ? void 0 : _rawConfig$installOpt4.exclude) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `installOptions.exclude` is now `exclude`.');
  }

  if (Array.isArray(rawConfig.webDependencies)) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] The `webDependencies` array is now `install`.');
  }

  if (rawConfig.knownEntrypoints) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `knownEntrypoints` is now `install`.');
  }

  if (rawConfig.entrypoints) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `entrypoints` is now `install`.');
  }

  if (rawConfig.include) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] All files are now included by default. "include" config is safe to remove.', 'Whitelist & include specific folders via "mount" build scripts.');
  } // Replaced!


  if (rawConfig.source || cliFlags.source) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `source` is now detected automatically, this config is safe to remove.');
  }

  if (rawConfig.stat || cliFlags.stat) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `stat` is now the default output, this config is safe to remove.');
  }

  if (rawConfig.scripts && Object.keys(rawConfig.scripts).filter(k => k.startsWith('lintall')).length > 0) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `scripts["lintall:..."]` has been renamed to scripts["run:..."]');
  }

  if (rawConfig.scripts && Object.keys(rawConfig.scripts).filter(k => k.startsWith('plugin:`')).length > 0) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `scripts["plugin:..."]` have been renamed to scripts["build:..."].');
  } // Removed!


  if ((_rawConfig$devOptions = rawConfig.devOptions) === null || _rawConfig$devOptions === void 0 ? void 0 : _rawConfig$devOptions.dist) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `devOptions.dist` is no longer required. This config is safe to remove.', `If you'd still like to host your src/ directory at the "/_dist/*" URL, create a mount script:',
      '    {"scripts": {"mount:src": "mount src --to /_dist_"}} `);
  }

  if (rawConfig.hash || cliFlags.hash) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `installOptions.hash` has been replaced by `snowpack build`.');
  }

  if (((_rawConfig$installOpt5 = rawConfig.installOptions) === null || _rawConfig$installOpt5 === void 0 ? void 0 : _rawConfig$installOpt5.nomodule) || cliFlags.nomodule) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `installOptions.nomodule` has been replaced by `snowpack build`.');
  }

  if (((_rawConfig$installOpt6 = rawConfig.installOptions) === null || _rawConfig$installOpt6 === void 0 ? void 0 : _rawConfig$installOpt6.nomoduleOutput) || cliFlags.nomoduleOutput) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `installOptions.nomoduleOutput` has been replaced by `snowpack build`.');
  }

  if (((_rawConfig$installOpt7 = rawConfig.installOptions) === null || _rawConfig$installOpt7 === void 0 ? void 0 : _rawConfig$installOpt7.babel) || cliFlags.babel) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `installOptions.babel` has been replaced by `snowpack build`.');
  }

  if ((_rawConfig$installOpt8 = rawConfig.installOptions) === null || _rawConfig$installOpt8 === void 0 ? void 0 : _rawConfig$installOpt8.optimize) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `installOptions.optimize` has been replaced by `snowpack build` minification.');
  }

  if (((_rawConfig$installOpt9 = rawConfig.installOptions) === null || _rawConfig$installOpt9 === void 0 ? void 0 : _rawConfig$installOpt9.strict) || cliFlags.strict) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `installOptions.strict` is no longer supported.');
  }

  if ((_rawConfig$installOpt10 = rawConfig.installOptions) === null || _rawConfig$installOpt10 === void 0 ? void 0 : _rawConfig$installOpt10.alias) {
    handleDeprecatedConfigError('[New in v2.7] `installOptions.alias` has been moved to a top-level `alias` config. (https://snowpack.dev#all-config-options)');
  }
}

function validatePlugin(plugin) {
  const pluginName = plugin.name;

  if (plugin.resolve && !plugin.load) {
    handleConfigError(`[plugin=${pluginName}] "resolve" config found but "load()" method missing.`);
  }

  if (!plugin.resolve && plugin.load) {
    handleConfigError(`[plugin=${pluginName}] "load" method found but "resolve()" config missing.`);
  }

  if (plugin.resolve && !Array.isArray(plugin.resolve.input)) {
    handleConfigError(`[plugin=${pluginName}] "resolve.input" should be an array of input file extensions.`);
  }

  if (plugin.resolve && !Array.isArray(plugin.resolve.output)) {
    handleConfigError(`[plugin=${pluginName}] "resolve.output" should be an array of output file extensions.`);
  }
}

function validatePluginLoadResult(plugin, result) {
  const pluginName = plugin.name;

  if (!result) {
    return;
  }

  if (typeof result === 'string' && plugin.resolve.output.length !== 1) {
    handleConfigError(`[plugin=${pluginName}] "load()" returned a string, but "resolve.output" contains multiple possible outputs. If multiple outputs are expected, the object return format is required.`);
  }

  const unexpectedOutput = typeof result === 'object' && Object.keys(result).find(fileExt => !plugin.resolve.output.includes(fileExt));

  if (unexpectedOutput) {
    handleConfigError(`[plugin=${pluginName}] "load()" returned entry "${unexpectedOutput}" not found in "resolve.output": ${plugin.resolve.output}`);
  }
}
function createConfiguration(config) {
  const {
    errors: validationErrors
  } = jsonschema.validate(config, configSchema, {
    propertyName: CONFIG_NAME,
    allowUnknownAttributes: false
  });

  if (validationErrors.length > 0) {
    return [validationErrors, undefined];
  }

  const mergedConfig = merge.all([DEFAULT_CONFIG, config]);
  return [null, normalizeConfig(mergedConfig)];
}
function loadAndValidateConfig(flags, pkgManifest) {
  const explorerSync = cosmiconfig.cosmiconfigSync(CONFIG_NAME, {
    // only support these 3 types of config for now
    searchPlaces: ['package.json', 'snowpack.config.js', 'snowpack.config.json'],
    // don't support crawling up the folder tree:
    stopDir: path.dirname(process.cwd())
  });
  let result; // if user specified --config path, load that

  if (flags.config) {
    result = explorerSync.load(path.resolve(process.cwd(), flags.config));

    if (!result) {
      handleConfigError(`Could not locate Snowpack config at ${flags.config}`);
    }
  } // If no config was found above, search for one.


  result = result || explorerSync.search(); // If still no config found, assume none exists and use the default config.

  if (!result || !result.config || result.isEmpty) {
    result = {
      config: _objectSpread2({}, DEFAULT_CONFIG)
    };
  } // validate against schema; throw helpful user if invalid


  const config = result.config;
  validateConfigAgainstV1(config, flags);
  const cliConfig = expandCliFlags(flags);
  let extendConfig = {};

  if (config.extends) {
    const extendConfigLoc = config.extends.startsWith('.') ? path.resolve(path.dirname(result.filepath), config.extends) : require.resolve(config.extends, {
      paths: [process.cwd()]
    });
    const extendResult = explorerSync.load(extendConfigLoc);

    if (!extendResult) {
      handleConfigError(`Could not locate Snowpack config at ${flags.config}`);
      process.exit(1);
    }

    extendConfig = extendResult.config;
    const extendValidation = jsonschema.validate(extendConfig, configSchema, {
      allowUnknownAttributes: false,
      propertyName: CONFIG_NAME
    });

    if (extendValidation.errors && extendValidation.errors.length > 0) {
      handleValidationErrors(result.filepath, extendValidation.errors);
      process.exit(1);
    }

    if (extendConfig.plugins) {
      const extendConfgDir = path.dirname(extendConfigLoc);
      extendConfig.plugins = extendConfig.plugins.map(plugin => {
        const name = Array.isArray(plugin) ? plugin[0] : plugin;
        const absName = path.isAbsolute(name) ? name : require.resolve(name, {
          paths: [extendConfgDir]
        });
        return Array.isArray(plugin) ? plugin.splice(0, 1, absName) : absName;
      });
    }
  } // if valid, apply config over defaults


  const mergedConfig = merge.all([pkgManifest.homepage ? {
    buildOptions: {
      baseUrl: pkgManifest.homepage
    }
  } : {}, extendConfig, {
    webDependencies: pkgManifest.webDependencies
  }, config, cliConfig]);

  for (const webDependencyName of Object.keys(mergedConfig.webDependencies || {})) {
    if (pkgManifest.dependencies && pkgManifest.dependencies[webDependencyName]) {
      handleConfigError(`"${webDependencyName}" is included in "webDependencies". Please remove it from your package.json "dependencies" config.`);
    }

    if (pkgManifest.devDependencies && pkgManifest.devDependencies[webDependencyName]) {
      handleConfigError(`"${webDependencyName}" is included in "webDependencies". Please remove it from your package.json "devDependencies" config.`);
    }
  }

  const [validationErrors, configResult] = createConfiguration(mergedConfig);

  if (validationErrors) {
    handleValidationErrors(result.filepath, validationErrors);
    process.exit(1);
  }

  return configResult;
}
function removeLeadingSlash(path) {
  return path.replace(/^[/\\]+/, '');
}
function removeTrailingSlash(path) {
  return path.replace(/[/\\]+$/, '');
}
function addLeadingSlash(path) {
  return path.replace(/^\/?/, '/');
}
function addTrailingSlash(path) {
  return path.replace(/\/?$/, '/');
}

function getInputsFromOutput(fileLoc, plugins) {
  const {
    baseExt
  } = getExt(fileLoc);
  const potentialInputs = new Set([fileLoc]);

  for (const plugin of plugins) {
    if (plugin.resolve && plugin.resolve.output.includes(baseExt)) {
      plugin.resolve.input.forEach(inp => potentialInputs.add(fileLoc.replace(baseExt, inp)));
    }
  }

  return Array.from(potentialInputs);
}
/**
 * Build Plugin First Pass: If a plugin defines a
 * `resolve` object, check it against the current
 * file's extension. If it matches, call the load()
 * functon and return it's result.
 *
 * If no match is found, fall back to just reading
 * the file from disk and return it.
 */

async function runPipelineLoadStep(srcPath, {
  plugins,
  messageBus,
  isDev,
  isHmrEnabled
}) {
  const srcExt = getExt(srcPath).baseExt;

  for (const step of plugins) {
    if (!step.resolve || !step.resolve.input.includes(srcExt)) {
      continue;
    }

    if (!step.load) {
      continue;
    }

    const result = await step.load({
      fileExt: srcExt,
      filePath: srcPath,
      isDev,
      isHmrEnabled,
      // @ts-ignore: internal API only
      log: (msg, data = {}) => {
        messageBus.emit(msg, _objectSpread2(_objectSpread2({}, data), {}, {
          id: step.name,
          msg: data.msg && `${data.msg} [${path.relative(process.cwd(), srcPath)}]`
        }));
      }
    });
    validatePluginLoadResult(step, result);

    if (typeof result === 'string') {
      const mainOutputExt = step.resolve.output[0];
      return {
        [mainOutputExt]: result
      };
    } else if (result && typeof result === 'object') {
      return result;
    } else {
      continue;
    }
  }

  return {
    [srcExt]: await fs.promises.readFile(srcPath, getEncodingType(srcExt))
  };
}
/**
 * Build Plugin Second Pass: If a plugin defines a
 * transform() method,call it. Transform cannot change
 * the file extension, and was designed to run on
 * every file type and return null/undefined if no
 * change needed.
 */


async function runPipelineTransformStep(output, srcPath, {
  plugins,
  messageBus,
  isDev
}) {
  const srcExt = getExt(srcPath).baseExt;
  const rootFileName = path.basename(srcPath).replace(srcExt, '');

  for (const step of plugins) {
    if (!step.transform) {
      continue;
    }

    for (const destExt of Object.keys(output)) {
      const destBuildFile = output[destExt];
      const result = await step.transform({
        contents: destBuildFile,
        fileExt: destExt,
        filePath: rootFileName + destExt,
        isDev,
        // @ts-ignore: internal API only
        log: (msg, data = {}) => {
          messageBus.emit(msg, _objectSpread2(_objectSpread2({}, data), {}, {
            id: step.name,
            msg: data.msg && `[${srcPath}] ${data.msg}`
          }));
        },
        // @ts-ignore: Deprecated
        urlPath: `./${path.basename(rootFileName + destExt)}`
      });

      if (typeof result === 'string') {
        output[destExt] = result;
      } else if (result && typeof result === 'object' && result.result) {
        output[destExt] = result.result;
      }
    }
  }

  return output;
}

async function runPipelineOptimizeStep(buildDirectory, {
  plugins,
  messageBus
}) {
  for (const step of plugins) {
    if (!step.optimize) {
      continue;
    }

    await step.optimize({
      buildDirectory,
      // @ts-ignore: internal API only
      log: msg => {
        messageBus.emit('WORKER_MSG', {
          id: step.name,
          level: 'log',
          msg
        });
      }
    });
  }

  return null;
}
/** Core Snowpack file pipeline builder */

async function buildFile(srcPath, buildFileOptions) {
  // Pass 1: Find the first plugin to load this file, and return the result
  const loadResult = await runPipelineLoadStep(srcPath, buildFileOptions); // Pass 2: Pass that result through every plugin transfomr() method.

  const transformResult = await runPipelineTransformStep(loadResult, srcPath, buildFileOptions); // Return the final build result.

  return transformResult;
}

const cwd$1 = process.cwd();
/** Perform a file disk lookup for the requested import specifier. */

function getImportStats(dirLoc, spec) {
  const importedFileOnDisk = path.resolve(dirLoc, spec);

  try {
    return fs__default.statSync(importedFileOnDisk);
  } catch (err) {// file doesn't exist, that's fine
  }

  return false;
}
/** Resolve an import based on the state of the file/folder found on disk. */

function resolveSourceSpecifier(spec, stats, config) {
  if (stats && stats.isDirectory()) {
    const trailingSlash = spec.endsWith('/') ? '' : '/';
    spec = spec + trailingSlash + 'index.js';
  } else if (!stats && !spec.endsWith('.js') && !spec.endsWith('.css')) {
    spec = spec + '.js';
  }

  const {
    baseExt
  } = getExt(spec);
  const extToReplace = config._extensionMap[baseExt] || srcFileExtensionMapping[baseExt];

  if (extToReplace) {
    spec = replaceExt(spec, extToReplace);
  }

  return spec;
}
/**
 * Create a import resolver function, which converts any import relative to the given file at "fileLoc"
 * to a proper URL. Returns false if no matching import was found, which usually indicates a package
 * not found in the import map.
 */


function createImportResolver({
  fileLoc,
  dependencyImportMap,
  config
}) {
  return function importResolver(spec) {
    if (URL_HAS_PROTOCOL_REGEX.test(spec)) {
      return spec;
    }

    if (spec.startsWith('/') || spec.startsWith('./') || spec.startsWith('../')) {
      const importStats = getImportStats(path.dirname(fileLoc), spec);
      spec = resolveSourceSpecifier(spec, importStats, config);
      return spec;
    }

    const aliasEntry = findMatchingAliasEntry(config, spec);

    if (aliasEntry && aliasEntry.type === 'path') {
      const {
        from,
        to
      } = aliasEntry;
      let result = spec.replace(from, to);
      const importStats = getImportStats(cwd$1, result);
      result = resolveSourceSpecifier(result, importStats, config);
      result = path.posix.relative(path.dirname(fileLoc), result);

      if (!result.startsWith('.')) {
        result = './' + result;
      }

      return result;
    }

    if (dependencyImportMap) {
      // NOTE: We don't need special handling for an alias here, since the aliased "from"
      // is already the key in the import map. The aliased "to" value is also an entry.
      const importMapEntry = dependencyImportMap.imports[spec];

      if (importMapEntry) {
        let resolved = path.posix.resolve(config.buildOptions.webModulesUrl, importMapEntry); // Windows fix: temporarily use backslashes until fully resolved (will be transformed to forward slashes later)

        if (path.sep === '\\') {
          resolved = resolved.replace(/\//g, '\\');
        }

        return resolved;
      }
    }

    return false;
  };
}

const {
  parse
} = require('es-module-lexer');

function spliceString(source, withSlice, start, end) {
  return source.slice(0, start) + (withSlice || '') + source.slice(end);
}

async function scanCodeImportsExports(code) {
  const [imports] = await parse(code);
  return imports.filter(imp => {
    //imp.d = -2 = import.meta.url = we can skip this for now
    if (imp.d === -2) {
      return false;
    } // imp.d > -1 === dynamic import


    if (imp.d > -1) {
      const importStatement = code.substring(imp.s, imp.e);
      const importSpecifierMatch = importStatement.match(/^\s*['"](.*)['"]\s*$/m);
      return !!importSpecifierMatch;
    }

    return true;
  });
}
async function transformEsmImports(_code, replaceImport) {
  const imports = await scanCodeImportsExports(_code);
  let rewrittenCode = _code;

  for (const imp of imports.reverse()) {
    let spec = rewrittenCode.substring(imp.s, imp.e);

    if (imp.d > -1) {
      const importSpecifierMatch = spec.match(/^\s*['"](.*)['"]\s*$/m);
      spec = importSpecifierMatch[1];
    }

    let rewrittenImport = replaceImport(spec);

    if (imp.d > -1) {
      rewrittenImport = JSON.stringify(rewrittenImport);
    }

    rewrittenCode = spliceString(rewrittenCode, rewrittenImport, imp.s, imp.e);
  }

  return rewrittenCode;
}

async function transformHtmlImports(code, replaceImport) {
  let rewrittenCode = code;
  let match;
  const importRegex = new RegExp(HTML_JS_REGEX);

  while (match = importRegex.exec(rewrittenCode)) {
    const [, scriptTag, scriptCode] = match; // Only transform a script element if it contains inlined code / is not empty.

    if (scriptCode.trim()) {
      rewrittenCode = spliceString(rewrittenCode, await transformEsmImports(scriptCode, replaceImport), match.index + scriptTag.length, match.index + scriptTag.length + scriptCode.length);
    }
  }

  return rewrittenCode;
}

async function transformFileImports({
  baseExt,
  contents
}, replaceImport) {
  if (baseExt === '.js') {
    return transformEsmImports(contents, replaceImport);
  }

  if (baseExt === '.html') {
    return transformHtmlImports(contents, replaceImport);
  }

  throw new Error(`Incompatible filetype: cannot scan ${baseExt} files for ESM imports. This is most likely an error within Snowpack.`);
}

async function installOptimizedDependencies(allFilesToResolveImports, installDest, commandOptions) {
  var _commandOptions$confi;

  console.log(colors.yellow('! installing dependencies...'));
  const installConfig = merge__default(commandOptions.config, {
    installOptions: {
      dest: installDest,
      env: {
        NODE_ENV: process.env.NODE_ENV || 'production'
      },
      treeshake: (_commandOptions$confi = commandOptions.config.installOptions.treeshake) !== null && _commandOptions$confi !== void 0 ? _commandOptions$confi : true
    }
  }); // 1. Scan imports from your final built JS files.

  const installTargets = await getInstallTargets(installConfig, Object.values(allFilesToResolveImports)); // 2. Install dependencies, based on the scan of your final build.

  const installResult = await run(_objectSpread2(_objectSpread2({}, commandOptions), {}, {
    installTargets,
    config: installConfig
  })); // 3. Print stats immediate after install output.

  if (installResult.stats) {
    console.log(printStats(installResult.stats));
  }

  return installResult;
}

async function command$1(commandOptions) {
  const {
    cwd,
    config
  } = commandOptions;
  const messageBus = new events.EventEmitter(); // TODO: update this with a more robust / typed log event

  function logEvent({
    level,
    id,
    msg,
    args
  }) {
    let logger = console.log;

    let color = stdout => stdout;

    if (level === 'warn') {
      logger = console.warn;
      color = colors.yellow;
    }

    if (level === 'error') {
      color = colors.red;
      logger = console.error;
    }

    const output = msg || util.format.apply(util, args);
    logger(`${id ? colors.blue(`[${id}] `) : ''}${color(output)}`);
  }

  messageBus.on('CONSOLE', logEvent);
  messageBus.on('WORKER_COMPLETE', logEvent);
  messageBus.on('WORKER_MSG', logEvent);
  messageBus.on('WORKER_RESET', logEvent);
  messageBus.on('WORKER_START', logEvent);
  messageBus.on('WORKER_UPDATE', logEvent);
  const buildDirectoryLoc = config.devOptions.out;
  const internalFilesBuildLoc = path.join(buildDirectoryLoc, config.buildOptions.metaDir);

  if (config.buildOptions.clean) {
    rimraf.sync(buildDirectoryLoc);
  }

  mkdirp.sync(buildDirectoryLoc);
  mkdirp.sync(internalFilesBuildLoc);
  let relDest = path.relative(cwd, config.devOptions.out);

  if (!relDest.startsWith(`..${path.sep}`)) {
    relDest = `.${path.sep}` + relDest;
  }

  for (const runPlugin of config.plugins) {
    if (runPlugin.run) {
      await runPlugin.run({
        isDev: false,
        isHmrEnabled: false,
        // @ts-ignore: internal API only
        log: (msg, data = {}) => {
          messageBus.emit(msg, _objectSpread2(_objectSpread2({}, data), {}, {
            id: runPlugin.name
          }));
        }
      }).catch(err => {
        messageBus.emit('CONSOLE', _objectSpread2({
          level: 'error',
          id: runPlugin.name
        }, err));
      });
    }
  } // Write the `import.meta.env` contents file to disk


  await fs.promises.writeFile(path.join(internalFilesBuildLoc, 'env.js'), generateEnvModule('production'));
  const includeFileSets = [];

  for (const [fromDisk, toUrl] of Object.entries(config.mount)) {
    const dirDisk = path.resolve(cwd, fromDisk);
    const dirDest = path.resolve(buildDirectoryLoc, removeLeadingSlash(toUrl));
    const allFiles = glob.sync(`**/*`, {
      ignore: config.exclude,
      cwd: dirDisk,
      absolute: true,
      nodir: true,
      dot: true
    });
    const allBuildNeededFiles = [];
    await Promise.all(allFiles.map(async f => {
      f = path.resolve(f); // this is necessary since glob.sync() returns paths with / on windows.  path.resolve() will switch them to the native path separator.

      allBuildNeededFiles.push(f);
    }));
    includeFileSets.push([dirDisk, dirDest, allBuildNeededFiles]);
  }

  const allBuiltFromFiles = new Set();
  const allFilesToResolveImports = {};
  console.log(colors.yellow('! building source...'));
  const buildStart = perf_hooks.performance.now();

  for (const [dirDisk, dirDest, allFiles] of includeFileSets) {
    for (const locOnDisk of allFiles) {
      const {
        baseExt: fileExt
      } = getExt(locOnDisk);
      let outLoc = locOnDisk.replace(dirDisk, dirDest);
      let builtLocOnDisk = locOnDisk;
      const extToReplace = config._extensionMap[fileExt] || srcFileExtensionMapping[fileExt];

      if (extToReplace) {
        outLoc = replaceExt(outLoc, extToReplace);
        builtLocOnDisk = replaceExt(builtLocOnDisk, extToReplace);
      }

      const builtFileOutput = await buildFile(locOnDisk, {
        plugins: config.plugins,
        messageBus,
        isDev: false,
        isHmrEnabled: false
      });
      allBuiltFromFiles.add(locOnDisk);
      const {
        baseExt,
        expandedExt
      } = getExt(outLoc);
      let contents = builtFileOutput[config._extensionMap[fileExt] || srcFileExtensionMapping[fileExt] || fileExt];

      if (!contents) {
        continue;
      }

      const cssOutPath = outLoc.replace(/.js$/, '.css');
      mkdirp.sync(path.dirname(outLoc));

      switch (baseExt) {
        case '.js':
          {
            if (builtFileOutput['.css']) {
              await fs.promises.mkdir(path.dirname(cssOutPath), {
                recursive: true
              });
              await fs.promises.writeFile(cssOutPath, builtFileOutput['.css'], 'utf-8');
              contents = `import './${path.basename(cssOutPath)}';\n` + contents;
            }

            contents = wrapImportMeta({
              code: contents,
              env: true,
              isDev: false,
              hmr: false,
              config
            });
            allFilesToResolveImports[outLoc] = {
              baseExt,
              expandedExt,
              contents,
              locOnDisk
            };
            break;
          }

        case '.html':
          {
            contents = wrapHtmlResponse({
              code: contents,
              isDev: false,
              hmr: false,
              config
            });
            allFilesToResolveImports[outLoc] = {
              baseExt,
              expandedExt,
              contents,
              locOnDisk
            };
            break;
          }
      }

      await fs.promises.writeFile(outLoc, contents, getEncodingType(baseExt));
    }
  }

  stopEsbuild();
  const buildEnd = perf_hooks.performance.now();
  console.log(`${colors.green('✔')} ${colors.bold('snowpack')} build complete ${colors.dim(`[${((buildEnd - buildStart) / 1000).toFixed(2)}s]`)}`);
  const installDest = path.join(buildDirectoryLoc, config.buildOptions.webModulesUrl);
  const installResult = await installOptimizedDependencies(allFilesToResolveImports, installDest, commandOptions);

  if (!installResult.success || installResult.hasError) {
    process.exit(1);
  }

  const allImportProxyFiles = new Set();

  for (const [outLoc, file] of Object.entries(allFilesToResolveImports)) {
    const resolveImportSpecifier = createImportResolver({
      fileLoc: file.locOnDisk,
      dependencyImportMap: installResult.importMap,
      config
    });
    const resolvedCode = await transformFileImports(file, spec => {
      // Try to resolve the specifier to a known URL in the project
      let resolvedImportUrl = resolveImportSpecifier(spec);

      if (!resolvedImportUrl || url.parse(resolvedImportUrl).protocol) {
        return spec;
      }

      const extName = path.extname(resolvedImportUrl);
      const isProxyImport = extName && extName !== '.js'; // We treat ".proxy.js" files special: we need to make sure that they exist on disk
      // in the final build, so we mark them to be written to disk at the next step.

      const isAbsoluteUrlPath = path.isAbsolute(resolvedImportUrl);

      if (isProxyImport) {
        resolvedImportUrl = resolvedImportUrl + '.proxy.js';

        if (isAbsoluteUrlPath) {
          allImportProxyFiles.add(path.resolve(buildDirectoryLoc, removeLeadingSlash(resolvedImportUrl)));
        } else {
          allImportProxyFiles.add(path.resolve(path.dirname(outLoc), resolvedImportUrl));
        }
      } // When dealing with an absolute import path, we need to honor the baseUrl


      if (isAbsoluteUrlPath) {
        resolvedImportUrl = path.relative(path.dirname(outLoc), path.resolve(buildDirectoryLoc, removeLeadingSlash(resolvedImportUrl)));
      }

      if (!resolvedImportUrl.startsWith('.')) resolvedImportUrl = './' + removeLeadingSlash(resolvedImportUrl);
      return resolvedImportUrl.replace(/\\/g, '/'); // replace Windows backslashes at the end, after resolution
    });
    await fs.promises.mkdir(path.dirname(outLoc), {
      recursive: true
    });
    await fs.promises.writeFile(outLoc, resolvedCode);
  }

  for (const importProxyFileLoc of allImportProxyFiles) {
    const originalFileLoc = importProxyFileLoc.replace('.proxy.js', '');
    const proxiedExt = path.extname(originalFileLoc);
    const proxiedCode = await fs.promises.readFile(originalFileLoc, getEncodingType(proxiedExt));
    const proxiedUrl = originalFileLoc.substr(buildDirectoryLoc.length).replace(/\\/g, '/');
    const proxyCode = await wrapImportProxy({
      url: proxiedUrl,
      code: proxiedCode,
      isDev: false,
      hmr: false,
      config
    });
    await fs.promises.writeFile(importProxyFileLoc, proxyCode, getEncodingType('.js'));
  }

  await runPipelineOptimizeStep(buildDirectoryLoc, {
    plugins: config.plugins,
    messageBus,
    isDev: false,
    isHmrEnabled: false
  });

  if (config.buildOptions.minify) {
    const minifierStart = perf_hooks.performance.now();
    console.log(colors.yellow('! minifying javascript...'));
    let minifierService = await esbuild.startService();
    const allJsFiles = glob.sync(path.join(buildDirectoryLoc, '**/*.js'));

    for (const jsFile of allJsFiles) {
      const jsFileContents = await fs.promises.readFile(jsFile, 'utf-8');
      const {
        js
      } = await minifierService.transform(jsFileContents, {
        minify: true
      });
      js && (await fs.promises.writeFile(jsFile, js, 'utf-8'));
    }

    const minifierEnd = perf_hooks.performance.now();
    console.log(`${colors.green('✔')} ${colors.bold('snowpack')} minification complete ${colors.dim(`[${((minifierEnd - minifierStart) / 1000).toFixed(2)}s]`)}`);
    minifierService.stop();
  }

  process.stdout.write(`\n${colors.underline(colors.green(colors.bold('▶ Build Complete!')))}\n\n`);
}

class EsmHmrEngine {
  constructor(options = {}) {
    this.clients = new Set();
    this.dependencyTree = new Map();
    const wss = options.server ? new WebSocket.Server({
      noServer: true
    }) : new WebSocket.Server({
      port: 12321
    });

    if (options.server) {
      options.server.on('upgrade', (req, socket, head) => {
        // Only handle upgrades to ESM-HMR requests, ignore others.
        if (req.headers['sec-websocket-protocol'] !== 'esm-hmr') {
          return;
        }

        wss.handleUpgrade(req, socket, head, client => {
          wss.emit('connection', client, req);
        });
      });
    }

    wss.on('connection', client => {
      this.connectClient(client);
      this.registerListener(client);
    });
  }

  registerListener(client) {
    client.on('message', data => {
      const message = JSON.parse(data.toString());

      if (message.type === 'hotAccept') {
        const entry = this.getEntry(message.id, true);
        entry.isHmrAccepted = true;
        entry.isHmrEnabled = true;
      }
    });
  }

  createEntry(sourceUrl) {
    const newEntry = {
      dependencies: new Set(),
      dependents: new Set(),
      needsReplacement: false,
      isHmrEnabled: false,
      isHmrAccepted: false
    };
    this.dependencyTree.set(sourceUrl, newEntry);
    return newEntry;
  }

  getEntry(sourceUrl, createIfNotFound = false) {
    const result = this.dependencyTree.get(sourceUrl);

    if (result) {
      return result;
    }

    if (createIfNotFound) {
      return this.createEntry(sourceUrl);
    }

    return null;
  }

  setEntry(sourceUrl, imports, isHmrEnabled = false) {
    const result = this.getEntry(sourceUrl, true);
    const outdatedDependencies = new Set(result.dependencies);
    result.isHmrEnabled = isHmrEnabled;

    for (const importUrl of imports) {
      this.addRelationship(sourceUrl, importUrl);
      outdatedDependencies.delete(importUrl);
    }

    for (const importUrl of outdatedDependencies) {
      this.removeRelationship(sourceUrl, importUrl);
    }
  }

  removeRelationship(sourceUrl, importUrl) {
    let importResult = this.getEntry(importUrl);
    importResult && importResult.dependents.delete(sourceUrl);
    const sourceResult = this.getEntry(sourceUrl);
    sourceResult && sourceResult.dependencies.delete(importUrl);
  }

  addRelationship(sourceUrl, importUrl) {
    if (importUrl !== sourceUrl) {
      let importResult = this.getEntry(importUrl, true);
      importResult.dependents.add(sourceUrl);
      const sourceResult = this.getEntry(sourceUrl, true);
      sourceResult.dependencies.add(importUrl);
    }
  }

  markEntryForReplacement(entry, state) {
    entry.needsReplacement = state;
  }

  broadcastMessage(data) {
    this.clients.forEach(client => {
      if (client.readyState === WebSocket.OPEN) {
        client.send(JSON.stringify(data));
      } else {
        this.disconnectClient(client);
      }
    });
  }

  connectClient(client) {
    this.clients.add(client);
  }

  disconnectClient(client) {
    client.terminate();
    this.clients.delete(client);
  }

  disconnectAllClients() {
    for (const client of this.clients) {
      this.disconnectClient(client);
    }
  }

}

const cwd$2 = process.cwd();
/**
 * Get the actual port, based on the `defaultPort`.
 * If the default port was not available, then we'll prompt the user if its okay
 * to use the next available port.
 */

async function getPort(defaultPort) {
  const bestAvailablePort = await detectPort(defaultPort);

  if (defaultPort !== bestAvailablePort) {
    let useNextPort = false;

    if (process.stdout.isTTY) {
      const rl = readline.createInterface({
        input: process.stdin,
        output: process.stdout
      });
      useNextPort = await new Promise(resolve => {
        rl.question(colors.yellow(`! Port ${colors.bold(defaultPort)} not available. Run on port ${colors.bold(bestAvailablePort)} instead? (Y/n) `), answer => {
          resolve(!/^no?$/i.test(answer));
        });
      });
      rl.close();
    }

    if (!useNextPort) {
      console.error(colors.red(`✘ Port ${colors.bold(defaultPort)} not available. Use ${colors.bold('--port')} to specify a different port.`));
      console.error();
      process.exit(1);
    }
  }

  return bestAvailablePort;
}

function getStateString(workerState, isWatch) {
  if (workerState.state) {
    if (Array.isArray(workerState.state)) {
      return [colors[workerState.state[1]], workerState.state[0]];
    }

    return [colors.dim, workerState.state];
  }

  if (workerState.done) {
    return workerState.error ? [colors.red, 'FAIL'] : [colors.green, 'DONE'];
  }

  if (isWatch) {
    if (workerState.config.watch) {
      return [colors.dim, 'WATCH'];
    }
  }

  return [colors.dim, 'READY'];
}

const WORKER_BASE_STATE = {
  done: false,
  error: null,
  state: null,
  output: ''
};
function paint(bus, scripts, buildMode, devMode) {
  let port;
  let hostname;
  let protocol = '';
  let startTimeMs;
  let ips = [];
  let consoleOutput = '';
  let installOutput = '';
  let isInstalling = false;
  let hasBeenCleared = false;
  let missingWebModule = null;
  const allWorkerStates = {};
  const allFileBuilds = new Set();

  for (const script of scripts) {
    allWorkerStates[script] = _objectSpread2({}, WORKER_BASE_STATE);
  }

  function setupWorker(id) {
    if (!allWorkerStates[id]) {
      allWorkerStates[id] = _objectSpread2({}, WORKER_BASE_STATE);
    }
  }

  function repaint() {
    process.stdout.write(process.platform === 'win32' ? '\x1B[2J\x1B[0f' : '\x1B[2J\x1B[3J\x1B[H');
    process.stdout.write(`${colors.bold('Snowpack')}\n\n`); // Dashboard

    if (devMode) {
      const isServerStarted = startTimeMs > 0 && port > 0 && protocol;

      if (isServerStarted) {
        process.stdout.write(`  ${colors.bold(colors.cyan(`${protocol}//${hostname}:${port}`))}`);

        for (const ip of ips) {
          process.stdout.write(`${colors.cyan(` • `)}${colors.bold(colors.cyan(`${protocol}//${ip}:${port}`))}`);
        }

        process.stdout.write('\n');
        process.stdout.write(colors.dim(startTimeMs < 1000 ? `  Server started in ${startTimeMs}ms.` : `  Server started.`));

        if (allFileBuilds.size > 0) {
          process.stdout.write(colors.dim(` Building...`));
        }

        process.stdout.write('\n\n');
      } else {
        process.stdout.write(colors.dim(`  Server starting…`) + '\n\n');
      }
    }

    if (buildMode) {
      process.stdout.write('  ' + colors.bold(colors.cyan(buildMode.dest)));
      process.stdout.write(colors.dim(` Building your application...\n\n`));
    }

    let didPrintDashboard = false;

    for (const [script, workerState] of Object.entries(allWorkerStates)) {
      if (!workerState.state) {
        continue;
      }

      const dotLength = 34 - script.length;
      const dots = colors.dim(''.padEnd(dotLength, '.'));
      const [fmt, stateString] = getStateString(workerState, !!devMode);
      process.stdout.write(`  ${script}${dots}[${fmt(stateString)}]\n`);
      didPrintDashboard = true;
    }

    if (didPrintDashboard) {
      process.stdout.write('\n');
    }

    process.stdout.write('\n');

    if (isInstalling) {
      process.stdout.write(`${colors.underline(colors.bold('▼ snowpack install'))}\n\n`);
      process.stdout.write('  ' + installOutput.trim().replace(/\n/gm, '\n  '));
      process.stdout.write('\n\n');
      return;
    }

    if (missingWebModule) {
      const {
        id,
        pkgName,
        spec
      } = missingWebModule;
      process.stdout.write(`${colors.red(colors.underline(colors.bold('▼ Snowpack')))}\n\n`);

      if (devMode) {
        process.stdout.write(`  Package ${colors.bold(pkgName)} not found!\n`);
        process.stdout.write(colors.dim(`  in ${id}`));
        process.stdout.write(`\n\n`);
        process.stdout.write(`  ${colors.bold('Press Enter')} to automatically run ${colors.bold(isYarn(cwd$2) ? `yarn add ${pkgName}` : `npm install --save ${pkgName}`)}.\n`);
        process.stdout.write(`  Or, Exit Snowpack and install manually to continue.\n`);
      } else {
        process.stdout.write(`  Dependency ${colors.bold(spec)} not found!\n\n`); // process.stdout.write(
        //   `  Run ${colors.bold('snowpack install')} to install all required dependencies.\n\n`,
        // );

        process.exit(1);
      }

      return;
    }

    for (const [script, workerState] of Object.entries(allWorkerStates)) {
      if (workerState.output) {
        const colorsFn = Array.isArray(workerState.error) ? colors.red : colors.reset;
        process.stdout.write(`${colorsFn(colors.underline(colors.bold('▼ ' + script)))}\n\n`);
        process.stdout.write(workerState.output ? '  ' + workerState.output.trim().replace(/\n/gm, '\n  ') : hasBeenCleared ? colors.dim('  Output cleared.') : colors.dim('  No output, yet.'));
        process.stdout.write('\n\n');
      }
    }

    if (consoleOutput) {
      process.stdout.write(`${colors.underline(colors.bold('▼ Console'))}\n\n`);
      process.stdout.write(consoleOutput ? '  ' + consoleOutput.trim().replace(/\n/gm, '\n  ') : hasBeenCleared ? colors.dim('  Output cleared.') : colors.dim('  No output, yet.'));
      process.stdout.write('\n\n');
    }

    const overallStatus = Object.values(allWorkerStates).reduce((result, {
      done,
      error
    }) => {
      return {
        done: result.done && done,
        error: result.error || error
      };
    });

    if (overallStatus.error) {
      process.stdout.write(`${colors.underline(colors.red(colors.bold('▼ Result')))}\n\n`);
      process.stdout.write('  ⚠️  Finished, with errors.');
      process.stdout.write('\n\n');
      process.exit(1);
    }
  }

  bus.on('BUILD_FILE', ({
    id,
    isBuilding
  }) => {
    if (isBuilding) {
      allFileBuilds.add(path.relative(cwd$2, id));
    } else {
      allFileBuilds.delete(path.relative(cwd$2, id));
    }

    repaint();
  });
  bus.on('WORKER_START', ({
    id,
    state
  }) => {
    setupWorker(id);
    allWorkerStates[id].state = state || ['RUNNING', 'yellow'];
    repaint();
  });
  bus.on('WORKER_MSG', ({
    id,
    msg
  }) => {
    setupWorker(id);
    allWorkerStates[id].output += msg;
    repaint();
  });
  bus.on('WORKER_UPDATE', ({
    id,
    state
  }) => {
    if (typeof state !== undefined) {
      setupWorker(id);
      allWorkerStates[id].state = state;
    }

    repaint();
  });
  bus.on('WORKER_COMPLETE', ({
    id,
    error
  }) => {
    allWorkerStates[id].state = ['DONE', 'green'];
    allWorkerStates[id].done = true;
    allWorkerStates[id].error = allWorkerStates[id].error || error;
    repaint();
  });
  bus.on('WORKER_RESET', ({
    id
  }) => {
    allWorkerStates[id] = _objectSpread2({}, WORKER_BASE_STATE);
    repaint();
  });
  bus.on('CONSOLE', ({
    level,
    args
  }) => {
    if (isInstalling) {
      const msg = util.format.apply(util, args);

      if (!msg.startsWith('[404] ')) {
        installOutput += msg;
      }
    } else {
      consoleOutput += `[${level}] ${util.format.apply(util, args)}\n`;
    }

    repaint();
  });
  bus.on('NEW_SESSION', () => {
    if (consoleOutput) {
      consoleOutput = ``;
      hasBeenCleared = true;
    } // Reset all per-file build scripts


    for (const script of scripts) {
      if (script.startsWith('build')) {
        setupWorker(script);
        allWorkerStates[script] = _objectSpread2({}, WORKER_BASE_STATE);
      }
    }

    repaint();
  });
  bus.on('INSTALLING', () => {
    isInstalling = true;
    installOutput = '';
    repaint();
  });
  bus.on('INSTALL_COMPLETE', () => {
    setTimeout(() => {
      missingWebModule = null;
      isInstalling = false;
      installOutput = '';
      consoleOutput = ``;
      hasBeenCleared = true;
      repaint();
    }, 2000);
  });
  bus.on('MISSING_WEB_MODULE', ({
    id,
    data
  }) => {
    if (!missingWebModule && data) {
      missingWebModule = _objectSpread2({
        id
      }, data);
    }

    if (missingWebModule && missingWebModule.id === id) {
      if (!data) {
        missingWebModule = null;
      } else {
        missingWebModule = _objectSpread2({
          id
        }, data);
      }
    }

    repaint();
  });
  bus.on('SERVER_START', info => {
    startTimeMs = info.startTimeMs;
    hostname = info.hostname;
    port = info.port;
    protocol = info.protocol;
    ips = info.ips;
    repaint();
  });

  if (devMode) {
    readline.emitKeypressEvents(process.stdin);
    process.stdin.on('keypress', (_, key) => {
      if (key.name !== 'return' && key.name !== 'enter') {
        return;
      }

      if (!missingWebModule) {
        return;
      }

      devMode.addPackage(missingWebModule.pkgName);
      repaint();
    });
  }

  repaint();
}

const HMR_DEV_CODE = fs.readFileSync(path.join(__dirname, '../assets/hmr.js'));

const DEFAULT_PROXY_ERROR_HANDLER = (err, req, res) => {
  const reqUrl = req.url;
  console.error(`✘ ${reqUrl}\n${err.message}`);
  sendError(req, res, 502);
};

function shouldProxy(pathPrefix, req) {
  const reqPath = decodeURI(url.parse(req.url).pathname);
  return reqPath.startsWith(pathPrefix);
}

const sendFile = (req, res, body, ext = '.html') => {
  var _req$headers$cacheCo;

  const ETag = etag(body, {
    weak: true
  });
  const contentType = mime.contentType(ext);
  const headers = {
    'Content-Type': contentType || 'application/octet-stream',
    'Access-Control-Allow-Origin': '*',
    ETag,
    Vary: 'Accept-Encoding'
  };

  if (req.headers['if-none-match'] === ETag) {
    res.writeHead(304, headers);
    res.end();
    return;
  }

  let acceptEncoding = req.headers['accept-encoding'] || '';

  if (((_req$headers$cacheCo = req.headers['cache-control']) === null || _req$headers$cacheCo === void 0 ? void 0 : _req$headers$cacheCo.includes('no-transform')) || ['HEAD', 'OPTIONS'].includes(req.method) || !contentType || !isCompressible(contentType)) {
    acceptEncoding = '';
  }

  function onError(err) {
    if (err) {
      res.end();
      console.error(colors.red(`  ✘ An error occurred while compressing ${colors.bold(req.url)}`), err);
    }
  }

  if (/\bgzip\b/.test(acceptEncoding) && stream.Readable.from) {
    const bodyStream = stream.Readable.from([body]);
    headers['Content-Encoding'] = 'gzip';
    res.writeHead(200, headers);
    stream.pipeline(bodyStream, zlib.createGzip(), res, onError);
    return;
  }

  res.writeHead(200, headers);
  res.write(body, getEncodingType(ext));
  res.end();
};

const sendError = (req, res, status) => {
  const contentType = mime.contentType(path.extname(req.url) || '.html');
  const headers = {
    'Content-Type': contentType || 'application/octet-stream',
    'Access-Control-Allow-Origin': '*',
    Vary: 'Accept-Encoding'
  };
  res.writeHead(status, headers);
  res.end();
};

function getUrlFromFile(mountedDirectories, fileLoc, config) {
  for (const [dirDisk, dirUrl] of mountedDirectories) {
    if (fileLoc.startsWith(dirDisk + path.sep)) {
      const {
        baseExt
      } = getExt(fileLoc);
      const resolvedDirUrl = dirUrl === '/' ? '' : dirUrl;
      return replaceExt(fileLoc.replace(dirDisk, resolvedDirUrl).replace(/[/\\]+/g, '/'), config._extensionMap[baseExt] || srcFileExtensionMapping[baseExt] || baseExt);
    }
  }

  return null;
}

let currentlyRunningCommand = null;
async function command$2(commandOptions) {
  const {
    cwd,
    config
  } = commandOptions;
  const {
    port: defaultPort,
    hostname,
    open,
    hmr: isHmr
  } = config.devOptions; // Start the startup timer!

  let serverStart = Date.now();
  const port = await getPort(defaultPort); // Reset the clock if we had to wait for the user to select a new port.

  if (port !== defaultPort) {
    serverStart = Date.now();
  }

  const inMemoryBuildCache = new Map();
  const filesBeingDeleted = new Set();
  const filesBeingBuilt = new Map();
  const messageBus = new events.EventEmitter();
  const mountedDirectories = Object.entries(config.mount).map(([fromDisk, toUrl]) => {
    return [path.resolve(cwd, fromDisk), toUrl];
  });

  console.log = (...args) => {
    messageBus.emit('CONSOLE', {
      level: 'log',
      args
    });
  };

  console.warn = (...args) => {
    messageBus.emit('CONSOLE', {
      level: 'warn',
      args
    });
  };

  console.error = (...args) => {
    messageBus.emit('CONSOLE', {
      level: 'error',
      args
    });
  }; // Start painting immediately, so we can surface errors & warnings to the
  // user, and they can watch the server starting up. Search for ”SERVER_START”
  // for the actual start event below.


  paint(messageBus, config.plugins.map(p => p.name), undefined, {
    addPackage: async pkgName => {
      isLiveReloadPaused = true;
      messageBus.emit('INSTALLING');
      currentlyRunningCommand = execa(isYarn(cwd) ? 'yarn' : 'npm', isYarn(cwd) ? ['add', pkgName] : ['install', '--save', pkgName], {
        env: npmRunPath.env(),
        extendEnv: true,
        shell: true,
        cwd
      });
      currentlyRunningCommand.stdout.on('data', data => process.stdout.write(data));
      currentlyRunningCommand.stderr.on('data', data => process.stderr.write(data));
      await currentlyRunningCommand;
      currentlyRunningCommand = command(installCommandOptions);
      await currentlyRunningCommand;
      await updateLockfileHash(DEV_DEPENDENCIES_DIR);
      await cacache.rm.all(BUILD_CACHE);
      inMemoryBuildCache.clear();
      currentlyRunningCommand = null;
      dependencyImportMap = JSON.parse(await fs.promises.readFile(dependencyImportMapLoc, {
        encoding: 'utf-8'
      }).catch(() => `{"imports": {}}`));
      messageBus.emit('INSTALL_COMPLETE');
      isLiveReloadPaused = false;
    }
  }); // Set the proper install options, in case an install is needed.

  const dependencyImportMapLoc = path.join(DEV_DEPENDENCIES_DIR, 'import-map.json');
  const installCommandOptions = merge__default(commandOptions, {
    config: {
      installOptions: {
        dest: DEV_DEPENDENCIES_DIR,
        env: {
          NODE_ENV: process.env.NODE_ENV || 'development'
        },
        treeshake: false
      }
    }
  }); // Start with a fresh install of your dependencies, if needed.

  if (!(await checkLockfileHash(DEV_DEPENDENCIES_DIR)) || !fs.existsSync(dependencyImportMapLoc)) {
    console.log(colors.yellow('! updating dependencies...'));
    await command(installCommandOptions);
    await updateLockfileHash(DEV_DEPENDENCIES_DIR);
  }

  let dependencyImportMap = {
    imports: {}
  };

  try {
    dependencyImportMap = JSON.parse(await fs.promises.readFile(dependencyImportMapLoc, {
      encoding: 'utf-8'
    }));
  } catch (err) {// no import-map found, safe to ignore
  }
  /** Rerun `snowpack install` while dev server is running */


  async function reinstallDependencies() {
    if (!currentlyRunningCommand) {
      isLiveReloadPaused = true;
      messageBus.emit('INSTALLING');
      currentlyRunningCommand = command(installCommandOptions);
      await currentlyRunningCommand.then(async () => {
        dependencyImportMap = JSON.parse(await fs.promises.readFile(dependencyImportMapLoc, {
          encoding: 'utf-8'
        }).catch(() => `{"imports": {}}`));
        await updateLockfileHash(DEV_DEPENDENCIES_DIR);
        await cacache.rm.all(BUILD_CACHE);
        inMemoryBuildCache.clear();
        messageBus.emit('INSTALL_COMPLETE');
        isLiveReloadPaused = false;
        currentlyRunningCommand = null;
      });
    }
  }

  const devProxies = {};
  config.proxy.forEach(([pathPrefix, proxyOptions]) => {
    const proxyServer = devProxies[pathPrefix] = HttpProxy.createProxyServer(proxyOptions);

    for (const [onEventName, eventHandler] of Object.entries(proxyOptions.on)) {
      proxyServer.on(onEventName, eventHandler);
    }

    if (!proxyOptions.on.error) {
      proxyServer.on('error', DEFAULT_PROXY_ERROR_HANDLER);
    }
  });

  const readCredentials = async cwd => {
    const [cert, key] = await Promise.all([fs.promises.readFile(path.join(cwd, 'snowpack.crt')), fs.promises.readFile(path.join(cwd, 'snowpack.key'))]);
    return {
      cert,
      key
    };
  };

  let credentials;

  if (config.devOptions.secure) {
    try {
      credentials = await readCredentials(cwd);
    } catch (e) {
      console.error(colors.red(`✘ No HTTPS credentials found! Missing Files:  ${colors.bold('snowpack.crt')}, ${colors.bold('snowpack.key')}`));
      console.log();
      console.log('You can automatically generate credentials for your project via either:');
      console.log();
      console.log(`  - ${colors.cyan('devcert')}: ${colors.yellow('npx devcert-cli generate localhost')}`);
      console.log('    https://github.com/davewasmer/devcert-cli (no install required)');
      console.log();
      console.log(`  - ${colors.cyan('mkcert')}: ${colors.yellow('mkcert -install && mkcert -key-file snowpack.key -cert-file snowpack.crt localhost')}`);
      console.log('    https://github.com/FiloSottile/mkcert (install required)');
      console.log();
      process.exit(1);
    }
  }

  for (const runPlugin of config.plugins) {
    if (runPlugin.run) {
      messageBus.emit('WORKER_START', {
        id: runPlugin.name
      });
      runPlugin.run({
        isDev: true,
        isHmrEnabled: isHmr,
        // @ts-ignore: internal API only
        log: (msg, data) => {
          messageBus.emit(msg, _objectSpread2(_objectSpread2({}, data), {}, {
            id: runPlugin.name
          }));
        }
      }).then(() => {
        messageBus.emit('WORKER_COMPLETE', {
          id: runPlugin.name,
          error: null
        });
      }).catch(err => {
        messageBus.emit('WORKER_COMPLETE', {
          id: runPlugin.name,
          error: err
        });
      });
    }
  }

  async function requestHandler(req, res) {
    const reqUrl = req.url;
    const reqUrlHmrParam = reqUrl.includes('?mtime=') && reqUrl.split('?')[1];
    let reqPath = decodeURI(url.parse(reqUrl).pathname);
    const originalReqPath = reqPath;
    let isProxyModule = false;

    if (reqPath.endsWith('.proxy.js')) {
      isProxyModule = true;
      reqPath = reqPath.replace('.proxy.js', '');
    } // const requestStart = Date.now();


    res.on('finish', () => {
      const {
        method,
        url
      } = req;
      const {
        statusCode
      } = res;

      if (statusCode !== 200) {
        messageBus.emit('SERVER_RESPONSE', {
          method,
          url,
          statusCode
        });
      }
    });

    if (reqPath === getMetaUrlPath('/hmr.js', true, config)) {
      sendFile(req, res, HMR_DEV_CODE, '.js');
      return;
    }

    if (reqPath === getMetaUrlPath('/env.js', true, config)) {
      sendFile(req, res, generateEnvModule('development'), '.js');
      return;
    }

    for (const [pathPrefix] of config.proxy) {
      if (!shouldProxy(pathPrefix, req)) {
        continue;
      }

      devProxies[pathPrefix].web(req, res);
      return;
    }

    const attemptedFileLoads = [];

    function attemptLoadFile(requestedFile) {
      if (attemptedFileLoads.includes(requestedFile)) {
        return Promise.resolve(null);
      }

      attemptedFileLoads.push(requestedFile);
      return fs.promises.stat(requestedFile).then(stat => stat.isFile() ? requestedFile : null).catch(() => null
      /* ignore */
      );
    }

    let requestedFileExt = path.parse(reqPath).ext.toLowerCase();
    let responseFileExt = requestedFileExt;
    let isRoute = !requestedFileExt || requestedFileExt === '.html'; // Now that we've set isRoute properly, give `requestedFileExt` a fallback

    requestedFileExt = requestedFileExt || '.html';

    async function getFileFromUrl(reqPath) {
      if (reqPath.startsWith(config.buildOptions.webModulesUrl)) {
        const fileLoc = await attemptLoadFile(reqPath.replace(config.buildOptions.webModulesUrl, DEV_DEPENDENCIES_DIR));

        if (fileLoc) {
          return fileLoc;
        }
      }

      for (const [dirDisk, dirUrl] of mountedDirectories) {
        let requestedFile;

        if (dirUrl === '/') {
          requestedFile = path.join(dirDisk, reqPath);
        } else if (reqPath.startsWith(dirUrl)) {
          requestedFile = path.join(dirDisk, reqPath.replace(dirUrl, './'));
        } else {
          continue;
        }

        if (isRoute) {
          let fileLoc = (await attemptLoadFile(requestedFile + '.html')) || (await attemptLoadFile(requestedFile + 'index.html')) || (await attemptLoadFile(requestedFile + '/index.html'));

          if (!fileLoc && dirUrl === '/' && config.devOptions.fallback) {
            const fallbackFile = path.join(dirDisk, config.devOptions.fallback);
            fileLoc = await attemptLoadFile(fallbackFile);
          }

          if (fileLoc) {
            responseFileExt = '.html';
            return fileLoc;
          }
        } else {
          for (const potentialSourceFile of getInputsFromOutput(requestedFile, config.plugins)) {
            const fileLoc = await attemptLoadFile(potentialSourceFile);

            if (fileLoc) {
              return fileLoc;
            }
          }
        }
      }

      return null;
    }

    const fileLoc = await getFileFromUrl(reqPath);

    if (isRoute) {
      messageBus.emit('NEW_SESSION');
    }

    if (!fileLoc) {
      const prefix = colors.red('  ✘ ');
      console.error(`[404] ${reqUrl}\n${attemptedFileLoads.map(loc => prefix + loc).join('\n')}`);
      return sendError(req, res, 404);
    }
    /**
     * Given a file, build it. Building a file sends it through our internal file builder
     * pipeline, and outputs a build map representing the final build. A Build Map is used
     * because one source file can result in multiple built files (Example: .svelte -> .js & .css).
     */


    async function buildFile$1(fileLoc) {
      const existingBuilderPromise = filesBeingBuilt.get(fileLoc);

      if (existingBuilderPromise) {
        return existingBuilderPromise;
      }

      const fileBuilderPromise = (async () => {
        const builtFileOutput = await buildFile(fileLoc, {
          plugins: config.plugins,
          messageBus,
          isDev: true,
          isHmrEnabled: isHmr
        });
        inMemoryBuildCache.set(fileLoc, builtFileOutput);
        return builtFileOutput;
      })();

      filesBeingBuilt.set(fileLoc, fileBuilderPromise);

      try {
        messageBus.emit('BUILD_FILE', {
          id: fileLoc,
          isBuilding: true
        });
        return await fileBuilderPromise;
      } finally {
        filesBeingBuilt.delete(fileLoc);
        messageBus.emit('BUILD_FILE', {
          id: fileLoc,
          isBuilding: false
        });
      }
    }
    /**
     * Wrap Response: The same build result can be expressed in different ways based on
     * the URL. For example, "App.css" should return CSS but "App.css.proxy.js" should
     * return a JS representation of that CSS. This is handled in the wrap step.
     */


    async function wrapResponse(code, hasCssResource) {
      if (isRoute) {
        code = wrapHtmlResponse({
          code: code,
          isDev: true,
          hmr: isHmr,
          config
        });
      } else if (isProxyModule) {
        responseFileExt = '.js';
        code = await wrapImportProxy({
          url: reqPath,
          code,
          isDev: true,
          hmr: isHmr,
          config
        });
      } else if (responseFileExt === '.js') {
        code = wrapImportMeta({
          code,
          env: true,
          isDev: true,
          hmr: isHmr,
          config
        });
      }

      if (responseFileExt === '.js' && hasCssResource) {
        code = `import './${path.basename(reqPath).replace(/.js$/, '.css.proxy.js')}';\n` + code;
      }

      if (responseFileExt === '.js' && reqUrlHmrParam) {
        code = await transformEsmImports(code, imp => {
          const importUrl = path.posix.resolve(path.posix.dirname(reqPath), imp);
          const node = hmrEngine.getEntry(importUrl);

          if (node && node.needsReplacement) {
            hmrEngine.markEntryForReplacement(node, false);
            return `${imp}?${reqUrlHmrParam}`;
          }

          return imp;
        });
      }

      if (responseFileExt === '.js') {
        const isHmrEnabled = code.includes('import.meta.hot');
        const rawImports = await scanCodeImportsExports(code);
        const resolvedImports = rawImports.map(imp => {
          let spec = code.substring(imp.s, imp.e);

          if (imp.d > -1) {
            const importSpecifierMatch = spec.match(/^\s*['"](.*)['"]\s*$/m);
            spec = importSpecifierMatch[1];
          }

          return path.posix.resolve(path.posix.dirname(reqPath), spec);
        });
        hmrEngine.setEntry(originalReqPath, resolvedImports, isHmrEnabled);
      }

      return code;
    }
    /**
     * Resolve Imports: Resolved imports are based on the state of the file system, so
     * they can't be cached long-term with the build.
     */


    async function resolveResponseImports(fileLoc, responseExt, wrappedResponse) {
      let missingWebModule = null;
      const resolveImportSpecifier = createImportResolver({
        fileLoc,
        dependencyImportMap,
        config
      });
      wrappedResponse = await transformFileImports({
        locOnDisk: fileLoc,
        contents: wrappedResponse,
        baseExt: responseExt,
        expandedExt: getExt(fileLoc).expandedExt
      }, spec => {
        // Try to resolve the specifier to a known URL in the project
        const resolvedImportUrl = resolveImportSpecifier(spec);

        if (resolvedImportUrl) {
          const extName = path.extname(resolvedImportUrl);

          if (extName && extName !== '.js') {
            return resolvedImportUrl + '.proxy.js';
          }

          return resolvedImportUrl;
        } // If that fails, return a placeholder import and attempt to resolve.


        const [packageName] = parsePackageImportSpecifier(spec);
        const [depManifestLoc] = resolveDependencyManifest(packageName, cwd);
        const doesPackageExist = !!depManifestLoc;

        if (doesPackageExist) {
          reinstallDependencies();
        } else {
          missingWebModule = {
            spec: spec,
            pkgName: packageName
          };
        } // Return a placeholder while Snowpack goes out and tries to re-install (or warn)
        // on the missing package.


        return spec;
      });
      messageBus.emit('MISSING_WEB_MODULE', {
        id: fileLoc,
        data: missingWebModule
      });
      return wrappedResponse;
    }
    /**
     * Given a build, finalize it for the response. This involves running individual steps
     * needed to go from build result to sever response, including:
     *   - wrapResponse(): Wrap responses
     *   - resolveResponseImports(): Resolve all ESM imports
     */


    async function finalizeResponse(fileLoc, requestedFileExt, output) {
      // Verify that the requested file exists in the build output map.
      if (!output[requestedFileExt] || !Object.keys(output)) {
        return null;
      } // Wrap the response.


      const hasAttachedCss = requestedFileExt === '.js' && !!output['.css'];
      let wrappedResponse = await wrapResponse(output[requestedFileExt], hasAttachedCss); // Resolve imports.

      if (requestedFileExt === '.js' || requestedFileExt === '.html') {
        wrappedResponse = await resolveResponseImports(fileLoc, requestedFileExt, wrappedResponse);
      } // Return the finalized response.


      return wrappedResponse;
    } // 1. Check the hot build cache. If it's already found, then just serve it.


    let hotCachedResponse = inMemoryBuildCache.get(fileLoc);

    if (hotCachedResponse) {
      const responseContent = await finalizeResponse(fileLoc, requestedFileExt, hotCachedResponse);

      if (!responseContent) {
        sendError(req, res, 404);
        return;
      }

      sendFile(req, res, responseContent, responseFileExt);
      return;
    } // 2. Load the file from disk. We'll need it to check the cold cache or build from scratch.


    const fileContents = await fs.promises.readFile(fileLoc, getEncodingType(requestedFileExt)); // 3. Send dependencies directly, since they were already build & resolved at install time.

    if (reqPath.startsWith(config.buildOptions.webModulesUrl)) {
      sendFile(req, res, fileContents, responseFileExt);
      return;
    } // 4. Check the persistent cache. If found, serve it via a "trust-but-verify" strategy.
    // Build it after sending, and if it no longer matches then assume the entire cache is suspect.
    // In that case, clear the persistent cache and then force a live-reload of the page.


    const cachedBuildData = !filesBeingDeleted.has(fileLoc) && (await cacache.get(BUILD_CACHE, fileLoc).catch(() => null));

    if (cachedBuildData) {
      const {
        originalFileHash
      } = cachedBuildData.metadata;
      const newFileHash = etag(fileContents);

      if (originalFileHash === newFileHash) {
        const coldCachedResponse = JSON.parse(cachedBuildData.data.toString());
        inMemoryBuildCache.set(fileLoc, coldCachedResponse); // Trust...

        const wrappedResponse = await finalizeResponse(fileLoc, requestedFileExt, coldCachedResponse);

        if (!wrappedResponse) {
          sendError(req, res, 404);
          return;
        }

        sendFile(req, res, wrappedResponse, responseFileExt); // ...but verify.

        let checkFinalBuildResult = null;

        try {
          checkFinalBuildResult = await buildFile$1(fileLoc);
        } catch (err) {// safe to ignore, it will be surfaced later anyway
        } finally {
          if (!checkFinalBuildResult || !cachedBuildData.data.equals(Buffer.from(JSON.stringify(checkFinalBuildResult)))) {
            inMemoryBuildCache.clear();
            await cacache.rm.all(BUILD_CACHE);
            hmrEngine.broadcastMessage({
              type: 'reload'
            });
          }
        }

        return;
      }
    } // 5. Final option: build the file, serve it, and cache it.


    let responseContent;
    let responseOutput;

    try {
      responseOutput = await buildFile$1(fileLoc);
    } catch (err) {
      sendError(req, res, 500);
      return;
    }

    try {
      responseContent = await finalizeResponse(fileLoc, requestedFileExt, responseOutput);
    } catch (err) {
      console.error(reqPath, err);
      sendError(req, res, 500);
      return;
    }

    if (!responseContent) {
      sendError(req, res, 404);
      return;
    }

    sendFile(req, res, responseContent, responseFileExt);
    const originalFileHash = etag(fileContents);
    cacache.put(BUILD_CACHE, fileLoc, Buffer.from(JSON.stringify(responseOutput)), {
      metadata: {
        originalFileHash
      }
    });
  }

  const createServer = requestHandler => {
    if (credentials && config.proxy.length === 0) {
      return http2.createSecureServer(_objectSpread2(_objectSpread2({}, credentials), {}, {
        allowHTTP1: true
      }), requestHandler);
    } else if (credentials) {
      return https.createServer(credentials, requestHandler);
    }

    return http.createServer(requestHandler);
  };

  const server = createServer(async (req, res) => {
    try {
      return await requestHandler(req, res);
    } catch (err) {
      console.error(`[500] ${req.url}`);
      console.error(err);
      return sendError(req, res, 500);
    }
  }).on('error', err => {
    console.error(colors.red(`  ✘ Failed to start server at port ${colors.bold(port)}.`), err);
    server.close();
    process.exit(1);
  }).on('upgrade', (req, socket, head) => {
    config.proxy.forEach(([pathPrefix, proxyOptions]) => {
      var _proxyOptions$target;

      const isWebSocket = proxyOptions.ws || ((_proxyOptions$target = proxyOptions.target) === null || _proxyOptions$target === void 0 ? void 0 : _proxyOptions$target.toString().startsWith('ws'));

      if (isWebSocket && shouldProxy(pathPrefix, req)) {
        devProxies[pathPrefix].ws(req, socket, head);
        console.log('Upgrading to WebSocket');
      }
    });
  }).listen(port);
  const hmrEngine = new EsmHmrEngine({
    server
  });
  onProcessExit(() => {
    hmrEngine.disconnectAllClients();
  }); // Live Reload + File System Watching

  let isLiveReloadPaused = false;

  function updateOrBubble(url, visited) {
    if (visited.has(url)) {
      return;
    }

    visited.add(url);
    const node = hmrEngine.getEntry(url);

    if (node && node.isHmrEnabled) {
      hmrEngine.broadcastMessage({
        type: 'update',
        url
      });
    }

    if (node && node.isHmrAccepted) ; else if (node && node.dependents.size > 0) {
      hmrEngine.markEntryForReplacement(node, true);
      node.dependents.forEach(dep => updateOrBubble(dep, visited));
    } else {
      // We've reached the top, trigger a full page refresh
      hmrEngine.broadcastMessage({
        type: 'reload'
      });
    }
  }

  function handleHmrUpdate(fileLoc) {
    if (isLiveReloadPaused) {
      return;
    }

    let updateUrl = getUrlFromFile(mountedDirectories, fileLoc, config);

    if (!updateUrl) {
      return;
    } // Append ".proxy.js" to Non-JS files to match their registered URL in the client app.


    if (!updateUrl.endsWith('.js') && !updateUrl.endsWith('.module.css')) {
      updateUrl += '.proxy.js';
    } // Check if a virtual file exists in the resource cache (ex: CSS from a Svelte file)
    // If it does, mark it for HMR replacement but DONT trigger a separate HMR update event.
    // This is because a virtual resource doesn't actually exist on disk, so we need the main
    // resource (the JS) to load first. Only after that happens will the CSS exist.


    const virtualCssFileUrl = updateUrl.replace(/.js$/, '.css');
    const virtualNode = hmrEngine.getEntry(`${virtualCssFileUrl}.proxy.js`);

    if (virtualNode) {
      hmrEngine.markEntryForReplacement(virtualNode, true);
    } // If the changed file exists on the page, trigger a new HMR update.


    if (hmrEngine.getEntry(updateUrl)) {
      updateOrBubble(updateUrl, new Set());
      return;
    } // Otherwise, reload the page if the file exists in our hot cache (which means that the
    // file likely exists on the current page, but is not supported by HMR (HTML, image, etc)).


    if (inMemoryBuildCache.has(fileLoc)) {
      hmrEngine.broadcastMessage({
        type: 'reload'
      });
      return;
    }
  } // Announce server has started


  const ips = Object.values(os.networkInterfaces()).reduce((every, i) => [...every, ...(i || [])], []).filter(i => i.family === 'IPv4' && i.internal === false).map(i => i.address);
  const protocol = config.devOptions.secure ? 'https:' : 'http:';
  messageBus.emit('SERVER_START', {
    protocol,
    hostname,
    port,
    ips,
    startTimeMs: Date.now() - serverStart
  }); // Open the user's browser

  if (open !== 'none') await openInBrowser(protocol, hostname, port, open); // Start watching the file system.
  // Defer "chokidar" loading to here, to reduce impact on overall startup time

  const chokidar = await Promise.resolve().then(() => require('chokidar')); // Watch src files

  async function onWatchEvent(fileLoc) {
    handleHmrUpdate(fileLoc);
    inMemoryBuildCache.delete(fileLoc);
    filesBeingDeleted.add(fileLoc);
    await cacache.rm.entry(BUILD_CACHE, fileLoc);
    filesBeingDeleted.delete(fileLoc);
  }

  const watcher = chokidar.watch(mountedDirectories.map(([dirDisk]) => dirDisk), {
    ignored: config.exclude,
    persistent: true,
    ignoreInitial: true,
    disableGlobbing: false
  });
  watcher.on('add', fileLoc => onWatchEvent(fileLoc));
  watcher.on('change', fileLoc => onWatchEvent(fileLoc));
  watcher.on('unlink', fileLoc => onWatchEvent(fileLoc)); // Watch node_modules & rerun snowpack install if symlinked dep updates

  const symlinkedFileLocs = new Set(Object.keys(dependencyImportMap.imports).map(specifier => {
    const [packageName] = parsePackageImportSpecifier(specifier);
    return resolveDependencyManifest(packageName, cwd);
  }) // resolve symlink src location
  .filter(([_, packageManifest]) => packageManifest && !packageManifest['_id']) // only watch symlinked deps for now
  .map(([fileLoc]) => `${path.dirname(fileLoc)}/**`));

  function onDepWatchEvent() {
    reinstallDependencies().then(() => hmrEngine.broadcastMessage({
      type: 'reload'
    }));
  }

  const depWatcher = chokidar.watch([...symlinkedFileLocs], {
    cwd: '/',
    persistent: true,
    ignoreInitial: true,
    disableGlobbing: false
  });
  depWatcher.on('add', onDepWatchEvent);
  depWatcher.on('change', onDepWatchEvent);
  depWatcher.on('unlink', onDepWatchEvent);
  return new Promise(() => {});
}

const cwd$3 = process.cwd();

function printHelp() {
  console.log(`
${colors.bold(`snowpack`)} - A faster build system for the modern web.

  Snowpack is best configured via config file.
  But, most configuration can also be passed via CLI flags.
  📖 ${colors.dim('https://www.snowpack.dev/#configuration')}

${colors.bold('Commands:')}
  snowpack dev          Develop your app locally.
  snowpack build        Build your app for production.
  snowpack install      (Advanced) Install web-ready dependencies.

${colors.bold('Flags:')}
  --config [path]       Set the location of your project config file.
  --help                Show this help message.
  --version             Show the current version.
  --reload              Clear Snowpack's local cache (troubleshooting).
    `.trim());
}

async function cli(args) {
  // parse CLI flags
  const cliFlags = yargs(args, {
    array: ['install', 'env', 'exclude', 'externalPackage']
  });

  if (cliFlags.help) {
    printHelp();
    process.exit(0);
  }

  if (cliFlags.version) {
    console.log(require('../package.json').version);
    process.exit(0);
  }

  if (cliFlags.reload) {
    console.log(colors.yellow('! clearing cache...'));
    await clearCache();
  } // Load the current package manifest


  let pkgManifest;

  try {
    pkgManifest = require(path.join(cwd$3, 'package.json'));
  } catch (err) {
    console.log(colors.red('[ERROR] package.json required but no file was found.'));
    process.exit(1);
  }

  const cmd = cliFlags['_'][2]; // Set this early -- before config loading -- so that plugins see it.

  if (cmd === 'build') {
    process.env.NODE_ENV = process.env.NODE_ENV || 'production';
  }

  if (cmd === 'dev') {
    process.env.NODE_ENV = process.env.NODE_ENV || 'development';
  }

  const commandOptions = {
    cwd: cwd$3,
    config: loadAndValidateConfig(cliFlags, pkgManifest),
    lockfile: await readLockfile(cwd$3),
    pkgManifest
  };

  if (cmd === 'add') {
    await addCommand(cliFlags['_'][3], commandOptions);
    return;
  }

  if (cmd === 'rm') {
    await rmCommand(cliFlags['_'][3], commandOptions);
    return;
  }

  if (cliFlags['_'].length > 3) {
    console.log(`Unexpected multiple commands`);
    process.exit(1);
  }

  if (cmd === 'build') {
    await command$1(commandOptions);
    return;
  }

  if (cmd === 'dev') {
    await command$2(commandOptions);
    return;
  }

  if (cmd === 'install' || !cmd) {
    await command(commandOptions);
    return;
  }

  console.log(`Unrecognized command: ${cmd}`);
  process.exit(1);
}

exports.cli = cli;
exports.createConfiguration = createConfiguration;
exports.unstable_installCommand = install;
//# sourceMappingURL=index.js.map
